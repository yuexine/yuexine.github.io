{"pages":[],"posts":[{"title":"Guava学习笔记(三)","text":"以前我也没想过使用堆缓存或者使用堆外缓存，如果这对你是个知识盲区？ Guava Cache网上一搜有很多的教程，阐述了它的各种用法，我只是想将这些Guava Cache的知识压缩一下，连成一条线，轻松的记住。 场景由于它是JVM内存级别的缓存，特点就是快，缺点嘛也多，内存有限，垃圾回收问题，分布式问题等等。 适合存放少量，高频访问的数据。 使用存与读创建一个Cache容器 1234567private Cache&lt;String, User&gt; cache = CacheBuilder.newBuilder() .build(new CacheLoader&lt;String, User&gt;() { @Override public User load(String key) throws Exception { return null; } }); 想容器中存储数据 1cache.put(\"apple\", new User(\"apple\", 1)); 从Cache中读取数据 1234public void test1() { User u = cache.getIfPresent(\"apple\"); assertEquals(1, u.getAge());} 刷新之前在看亿级流量那本书里面提到了缓存用法中，有一种用法是Read-Through，意思是获取数据时，直接请求缓存，如果命中缓存则从缓存中返回，否则回源的数据源地址查询。 12345678910111213141516171819202122232425LoadingCache&lt;Key, Graph&gt; graphs = CacheBuilder.newBuilder() .maximumSize(1000) .refreshAfterWrite(1, TimeUnit.MINUTES) .build( @Override new CacheLoader&lt;Key, Graph&gt;() { public Graph load(Key key) { // no checked exception return getGraphFromDatabase(key); } @Override public ListenableFuture&lt;Graph&gt; reload(final Key key, Graph prevGraph) { if (neverNeedsRefresh(key)) { return Futures.immediateFuture(prevGraph); } else { // asynchronous! ListenableFutureTask&lt;Graph&gt; task = ListenableFutureTask.create(new Callable&lt;Graph&gt;() { public Graph call() { return getGraphFromDatabase(key); } }); executor.execute(task); return task; } } }); 这个是文档中给出的示例，就是采用这种Read-Through的方法使用缓存 上述的代码指定了刷新的时间每分钟，刷新没成功前，会返回旧值。 清理Guava提供了多种清理策略 大小这个大小还需要自己算– 12345678910111213LoadingCache&lt;Key, Graph&gt; graphs = CacheBuilder.newBuilder() .maximumWeight(100000) .weigher(new Weigher&lt;Key, Graph&gt;() { public int weigh(Key k, Graph g) { return g.vertices().size(); } }) .build( new CacheLoader&lt;Key, Graph&gt;() { public Graph load(Key key) { // no checked exception return createExpensiveGraph(key); } }); 数量按照缓存key数量 .maximumSize(3) 最近使用expireAfterAccess(long, TimeUnit) 最近写时间expireAfterWrite(long, TimeUnit) 垃圾回收器清理通过设置K和V为弱引用的方法，让垃圾回收器进行回收 CacheBuilder.weakKeys() CacheBuilder.weakValues() CacheBuilder.softValues() 软引用: 我也没懂 手动清理 Cache.invalidate(key) Cache.invalidateAll(keys) Cache.invalidateAll() 最后，可以添加Remove监听来收到数据清理时的通知 1234CacheBuilder.newBuilder() .expireAfterWrite(2, TimeUnit.MINUTES) .removalListener(removalListener) .build(loader); 统计打开统计 1CacheBuilder.recordStats() 获得统计数据 1CacheStats cacheStats = cache.stats(); 参考1. 官方文档2. 中文翻译3. Guava Cache用法介绍","link":"/2019/06/14/Guava学习笔记(三)/"},{"title":"Guava学习笔记(一)","text":"本节主要包含的内容为基础工具库的使用。 为什么学习Guava？Guava是Google的一套基础类库，学习它除了提高开发效率外，其它就是提升逼格了。 Using/avoiding null在Guava中有一个Optional抽象类，它和Jdk提供的功能差不多，用来避免使用null对象，jdk8中的Optional是不是从Guava抄来的？如果使用8以下版本的jdk，Guava倒也是一个选择。 上述图列出了Guava Optional class中包含的方法，大致上也分为了3类和jdk的一样，这里不做过多的赘述。 Preconditions这是Guava提供的一组类似断言的前置检查工具方法。 这些方法Guava强烈建议我们静态倒入。 1234567891011121314151617181920import static com.google.common.base.Preconditions.*;private int i = 5;private int j = 10;private String z = null; @Testpublic void test() { checkArgument(i &gt; j, \"message %s\", \"bad\"); checkNotNull(z); checkState(i &gt; j); //这个会抛出异常，不包含5 checkElementIndex(5, 5); //这个没有问题，包含5，这也是和上面的区别 checkPositionIndex(5, 5); checkPositionIndexes(-1, 3, 5);} 下图列出了方法名说明等，我把他们分为2类，一个是对值的校验，另一个是对数组位置的校验。 OrderingOrdering本身实现了比较器接口，所以可以结合Java的Collections类进行快速排序。主要使用场景用来快速构建较为复杂的排序逻辑，在Java8之后Comparator类新增了一些方法，也可以支持构建多级排序规则。 1public abstract class Ordering&lt;T&gt; implements Comparator&lt;T&gt; 创建 natural() 对可排序的类型做自然排序 12List&lt;Integer&gt; list = Arrays.asList(1, 5, 3, 8, 2);Collections.sort(list, Ordering.natural()); usingToString() 按对象的字符串形式进行字典排序 Ordering.from(Comparator) 使用预先的比较器进行构建 比较器链这个才是Ordering比较强的地方，可以由给定的比较器组合出其它的比较器，，可以做到多字段排序，更多详细的示例在参考中有描述 应用Ordering同时也提供了一组方法，可以用来直接操作集合，直接操作集合。 对比Java8的Comparator我觉得Guava Ordering最强的地方就是链式的组合多个比较器，从而可以做到多字段的比较，在Java8的Comparator对象中新增了 1default Comparator&lt;T&gt; thenComparing(Comparator&lt;? super T&gt; other) 同样也可以实现用多个字段比较。 Object methodsObject的方法主要有4个 equals用来判断2个对象是否相等，需要注意的是jdk util包中也有一个Objects对象，里面的euqals方法和这个是等效的 1Objects.equal(null, \"a\"); // returns false hashCodeGuava的Objects.hashCode(Object...)提供了一个比较实用的为一组对象生成HashCode toString也是一个比较好用的方法 12System.out.println(MoreObjects.toStringHelper(this).add(\"i\", i).toString());//输出 GuavaTest{i=5} compare/compareTo这个也挺有意思的，使用ComparisonChain对象创建一个多级比较，更多的介绍看文档 ThrowablesThrowables类的使用场景我还没想好，我觉得并不是一个必须使用的，文档上给了这么个示例 123456789try { someMethodThatCouldThrowAnything();} catch (IKnowWhatToDoWithThisException e) { handle(e); //1} catch (Throwable t) { Throwables.propagateIfInstanceOf(t, IOException.class); //2 Throwables.propagateIfInstanceOf(t, SQLException.class); //3 throw Throwables.propagate(t); //4} 上述代码中，标记1表示捕捉并处理了我们已知的异常，2和3表示如果捕捉的异常是IOException和SQLException则抛出这两个异常，4再抛出异常t 这一块我也不是很理解 参考1. Guava Ordering的使用2. Ordering与Java8排序比较","link":"/2019/06/11/Guava学习笔记(一)/"},{"title":"JUnit5入门学习(一)","text":"我很崇拜那些单元测试写的很6的同学。 JUnit4我也没系统的学过，也就是跟着写一写，今天脑子一热，想系统的了解一下JUnit框架的功能，于是打开了JUnit官方用户手册，也懒得看4了，不多说，直接上版本5。 什么是JUnit5和JUnit4相比，在结构上变化很大，JUnit5是由来自3个项目的多个模块组成的。 JUnit 5 = JUnit Platform + JUnit Jupiter + JUnit Vintage JUnit Platform: JUnit的基础平台，定义了TestEngine的API，以及从命令行运行的控制台 JUnit Jupiter: 组合了新的编程模型和扩展模型用在JUnit5中编写测试 JUnit Vintage: 提供了一个测试引擎用来运行3和4版本的测试用例 是不是到了6版本的时候，针对新版本做一个新的实现？这种设计还是值得借鉴的，把变化的与不变分开。 在Maven中集成JUnit5JUnit5需要Java8以上的运行环境 12345&lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter&lt;/artifactId&gt; &lt;version&gt;5.4.2&lt;/version&gt;&lt;/dependency&gt; 在Maven项目中通过集成上述的依赖就可以使用JUnit5提供的基本功能了。需要注意的是这个依赖包是一个组合jar，它是由junit-jupiter-api unit-jupiter-params junit-jupiter-engine组成 第一个JUnit5测试看上去是不是和JUnit4没什么区别？除了@Test包所在的位置不一样外 123456789101112import static org.junit.jupiter.api.Assertions.assertEquals;import org.junit.jupiter.api.Test;class MyFirstJUnitJupiterTests { @Test void addition() { assertEquals(2, 1 + 1); }} 参考1. 官方用户手册","link":"/2019/06/11/JUnit5入门学习(一)/"},{"title":"Guava学习笔记(二)","text":"本部分主要笔记Guava之Collections的用法 Immutable Collections不可变的对象有很多好处: 不受信任的库可以安全使用。 线程安全：可以被许多线程使用，没有竞争条件的风险。 不需要支持变异，并且可以通过该假设节省时间和空间。所有不可变的集合实现都比它们可变的兄弟节点更具内存效率 可以用作常量，期望它将保持固定。 防御性编程(defensive programming technique) Guava 为JDK里面的各个几何类都提供了一个不可变的版本 3种创建方式 使用copyOf() 使用of(): 1ImmutableSet.of(\"a\", \"b\", \"c\", \"a\", \"d\", \"b\") Builder 12345 public static final ImmutableSet&lt;Color&gt; GOOGLE_COLORS =ImmutableSet.&lt;Color&gt;builder() .addAll(WEBSAFE_COLORS) .add(new Color(0, 191, 255)) .build(); New Collection TypesGuava在JDK的基础上，重新定义了几个集合类型 Multiset我们知道Set集合取值是没有重复的，Multiset和Set的区别在于Multiset是可以存重复的值的 12345678910111213public void test2() { Multiset&lt;String&gt; multiset = HashMultiset.create(); multiset.add(\"apple\", 2); multiset.add(\"orange\"); System.out.println(multiset.count(\"apple\")); //2 System.out.println(multiset.setCount(\"apple\", 2, 5)); //true System.out.println(multiset.count(\"apple\")); //5 //第二个参数表示旧值，第三个参数表示新值，返回false表示设置失败，旧值校验不对 System.out.println(multiset.setCount(\"apple\", 2, 6)); //false System.out.println(multiset.count(\"apple\")); //5} 从上面的示例可以看出Multiset是一个很好用的计数容器。 Multimap这个集合对象也特别有意思，它和Map不同，Map结构是一个K对应一个V，而Mutilmap是一个K对应多个V 123456789public void test3() { Multimap&lt;String, String&gt; multimap = HashMultimap.create(); multimap.put(\"apple\", \"red\"); multimap.put(\"apple\", \"green\"); multimap.put(\"apple\", \"yellow\"); multimap.put(\"orange\", \"orange\"); Collection&lt;String&gt; attrs = multimap.get(\"apple\"); attrs.forEach(System.out::println);} 怎么样，挺有意思吧？同时Multimap还提供了一组视图方法，用来转换multimap对象的数据到其它的数据结构视图，这个就不穷举说明了，看文档 Muiltumap提供了多种实现 BiMapBiMap在Map的基础上，提供了一个reverse()方法，可以将Map的key和value值进行对掉。 12345678public void test4() { BiMap&lt;Integer, String&gt; biMap = HashBiMap.create(); biMap.put(1, \"apple\"); biMap.put(2, \"guava\"); biMap.put(3, \"kiwi\"); BiMap&lt;String, Integer&gt; biMapReverse = biMap.inverse(); assertEquals(1, biMapReverse.get(\"apple\")); //1} TableTable用来记录一个坐标的值 123456789public void test5() { Table&lt;String, String, Integer&gt; table = HashBasedTable.create(); table.put(\"1\", \"1\", 11); table.put(\"1\", \"2\", 12); table.put(\"1\", \"3\", 13); table.put(\"2\", \"1\", 21); table.put(\"2\", \"2\", 22); assertEquals(12, table.get(\"1\", \"2\"));} ClassToInstanceMapClassToInstanceMap提供了K为class，V为值的map类型，emmm，没想到应用场景 12345public void test6() { ClassToInstanceMap&lt;Number&gt; numberDefaults = MutableClassToInstanceMap.create(); numberDefaults.putInstance(Integer.class, Integer.valueOf(1)); numberDefaults.putInstance(Double.class, Double.valueOf(1));} RangeSetRangeSet用来处理一些连续的非空的range，当添加一个range到一个RangeSet之后，任何有连续的range将被自动合并，而空的range将被自动去除 12345678910public void test7() { RangeSet rangeSet = TreeRangeSet.create(); rangeSet.add(Range.closed(0, 10)); rangeSet.add(Range.closedOpen(10, 15)); rangeSet.add(Range.closedOpen(16, 18)); System.out.println(rangeSet);} RangeMap和RangeSet相比，RangeMap将Range作为了一个key，每一个Range对应一个值。 1234567public void test8() { RangeMap rangeMap = TreeRangeMap.create(); rangeMap.put(Range.closed(5, 10), \"apple\"); rangeMap.put(Range.closed(8, 12), \"banana\"); System.out.println(rangeMap);}//[[5..8)=apple, [8..12]=banana] Collection UtilitiesGuava为一些集合接口开发了一组工具类 Extension Utilities这个以后再看","link":"/2019/06/13/Guava学习笔记(二)/"},{"title":"JUnit5入门学习(三)","text":"接着看JUnit的写法。 测试接口与方法在Java8中，接口里面可以定义default方法，并且有自己的默认实现，同理，在编写测试类的时候，我们可以把测试方法和生命周期方法定义在接口中或者抽象类中, @BeforeAll 和 @AfterAll 出现在接口时，需要在测试类上声明@TestInstance(Lifecycle.PER_CLASS) 12345678910111213141516171819202122232425262728@TestInstance(Lifecycle.PER_CLASS)interface TestLifecycleLogger { static final Logger logger = Logger.getLogger(TestLifecycleLogger.class.getName()); @BeforeAll default void beforeAllTests() { logger.info(\"Before all tests\"); } @AfterAll default void afterAllTests() { logger.info(\"After all tests\"); } @BeforeEach default void beforeEachTest(TestInfo testInfo) { logger.info(() -&gt; String.format(\"About to execute [%s]\", testInfo.getDisplayName())); } @AfterEach default void afterEachTest(TestInfo testInfo) { logger.info(() -&gt; String.format(\"Finished executing [%s]\", testInfo.getDisplayName())); }} 更多完整的示例参考文档 带参数的测试前面提到过JUnit5内置了几个对象的依赖注入，除了这种方式可以传人测试参数外，JUnit5提供了带参数的测试 12345@ParameterizedTest@ValueSource(strings = { \"racecar\", \"radar\", \"able was I ere I saw elba\" })void palindromes(String candidate) { assertTrue(StringUtils.isPalindrome(candidate));} 带参数的测试会执行多次，会为每个参数都测试一遍，怎么样？是不是很实用的功能 支持的参数种类有很多，这里就不一一说明，文档写的很详细 测试模版我理解下来，这就是一个自定义的多参数化执行的测试 Demo 动态测试动态测试的意思是在运行时生成的测试用例，听过 @TestFactory来声明这是一个动态测试 12345678910111213141516171819202122232425262728293031@TestFactoryStream&lt;DynamicTest&gt; generateRandomNumberOfTests() { // Generates random positive integers between 0 and 100 until // a number evenly divisible by 7 is encountered. Iterator&lt;Integer&gt; inputGenerator = new Iterator&lt;Integer&gt;() { Random random = new Random(); int current; @Override public boolean hasNext() { current = random.nextInt(100); return current % 7 != 0; } @Override public Integer next() { return current; } }; // Generates display names like: input:5, input:37, input:85, etc. Function&lt;Integer, String&gt; displayNameGenerator = (input) -&gt; \"input:\" + input; // Executes tests based on the current input value. ThrowingConsumer&lt;Integer&gt; testExecutor = (input) -&gt; assertTrue(input % 7 != 0); // Returns a stream of dynamic tests. return DynamicTest.stream(inputGenerator, displayNameGenerator, testExecutor);} 对于这一块我也还不是很懂，后面在看 并行执行并行执行是通过参数配置来实现的，具体的配置方法后面再谈 12junit.jupiter.execution.parallel.enabled = truejunit.jupiter.execution.parallel.mode.default = concurrent 总结这一部分测试的写法相比之前常规的方式是不是好玩了一些？","link":"/2019/06/12/JUnit5入门学习(三)/"},{"title":"JUnit5入门学习(五)","text":"本节主要笔记扩展模块的相关知识 WhatJUnit5提供了一个扩展模型，它可以用来扩展JUnit的核心功能，本节重点看扩展模型的简单用法。分为定义和使用2个部分 定义JUnit5定义了一组可扩展的接口 通过实现这些接口，从而获得扩展的能力。 Conditional Test ExecutionExecutionCondition接口用来扩展测试是否执行或者跳过 123456public class TestCondition implements ExecutionCondition { @Override public ConditionEvaluationResult evaluateExecutionCondition(ExtensionContext context) { return ConditionEvaluationResult.enabled(\"allowed\"); }} Test Instance FactoriesTestInstanceFactory接口的用法我也还不清楚怎么用，可能是没有掌握@TestFactory原因 Test Instance Post-processingTestInstancePostProcessor接口用在执行测试方法之前做一些初始化的业务，执行顺序在BeforeEach 之前BeforeAll之后 Parameter ResolutionParameterResolver用来在运行时解析方法参数 Test Result Processing实现TestWatcher接口用来处理测试用例在各种结果下的业务处理，包括执行禁止，执行中断，执行成功或失败 Test Lifecycle Callbacks用在测试用例执行的各个阶段的回掉 Before and After Test Execution Callbacks用来在测试方法执行前后的回掉业务，文档中给出了一个记录测试用例执行时间的示例 Exception HandlingTestExecutionExceptionHandler接口用来处理测试过程中产生的异常 Providing Invocation Contexts for Test Templates略过 Keeping State in Extensions一个容器，用来记录测试过程中的需要暂存的数据 使用使用就很简单了 12345@Test@ExtendWith({ DatabaseExtension.class, WebServerExtension.class })class MyFirstTests { // ...} 或者 123456@Test@ExtendWith(DatabaseExtension.class)@ExtendWith(WebServerExtension.class)class MySecondTests { // ...} 总结JUnit5提供了相当丰富的一组扩展用来满足一些特别的测试场景，感觉挺好用的样子。","link":"/2019/06/13/JUnit5入门学习(五)/"},{"title":"JUnit5入门学习(六)","text":"总结篇 通过这两天阅读JUnit5的文档，收获还是蛮大的，扩展模块之后还有高级主题以及一些其它附带的介绍，也不想继续花时间去看了。(疲惫) 回顾这个学习的内容，大致上分为三块，第一个就是编写测试用例，里面的内容主要是通过各种注解去完成一个测试用例的编写，第二部分主要是运行测试用例，这里主要学习了在Maven中基于插件去配置与运行测试用例，第三部分是在第一部分的基础上，对于一些复杂测试场景提供了一组扩展的接口，通过这些接口，可以实现在测试的各个生命周期的业务逻辑实现。 此外JUnit5的这种软件整体架构的设计上，也有很多值得借鉴的地方。 更多JUnit5的坑可能留到项目开发过程中慢慢体会了。","link":"/2019/06/13/JUnit5入门学习(六)/"},{"title":"JUnit5入门学习(四)","text":"本节主要包含的主题是运行JUnit5测试用例 IDE运行我主要用到的集成开发环境是Intellij和VSCode Intellij新版的Intellij可以直接运行JUnit5 VSCode需要安装Java Test Runner插件 构建支持构建工具我通常使用Maven，这里需要注意的是对JUnit的配置相关 过滤在执行mvn test命令时过滤出我们想要执行的测试。 通过@Tag过滤123456789101112&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.0&lt;/version&gt; &lt;configuration&gt; &lt;groups&gt;acceptance | !feature-a&lt;/groups&gt; &lt;excludedGroups&gt;integration, regression&lt;/excludedGroups&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; groups中填写tag组合的表达式，指定过滤规则 通过类名进行过滤12345678910111213&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.0&lt;/version&gt; &lt;configuration&gt; &lt;excludes&gt; &lt;exclude/&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 类名过滤的写法 */Test.java */Test.java */Tests.java */TestCase.java 参数配置前面提过并行测试，里面西药配置JUnit参数，一种配置方式就在pom中设置 12345678910111213&lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.0&lt;/version&gt; &lt;configuration&gt; &lt;properties&gt; &lt;configurationParameters&gt; junit.jupiter.conditions.deactivate = * junit.jupiter.extensions.autodetection.enabled = true junit.jupiter.testinstance.lifecycle.default = per_class &lt;/configurationParameters&gt; &lt;/properties&gt; &lt;/configuration&gt;&lt;/plugin&gt; Tag表达式Tag表达式前面提到了用来编写过滤规则，这个比较简单，下面是来自文档的截图 范例 捕捉标准/错误输出略过","link":"/2019/06/13/JUnit5入门学习(四)/"},{"title":"Java注解知识整理","text":"本节主要大致整理一下注解的内容。 定义12public @interface TestAnnotation {} 元注解用来修饰注解的注解，对于这些元注解还是需要牢记 @Retention这个元注解表示注解的生命周期 分为源码阶段(SOURCE)，编译阶段(CLASS)和运行阶段(RUNTIME) @Documented非功能性的注解，表示要不要将此注解包含到javadoc中 @Target表示注解可以标记在什么位置，是类，还是方法还是等等 取值不一一说明 @Inherited被Inherited修饰的注解标记到class A上，class B继承自class A，那么class B也拥有了此标记。 @Repeatable被Repeatable修饰的注解表示当前注解可以重复的标记到目标位置 123456789101112131415161718192021@Target({ElementType.TYPE, ElementType.METHOD})@Retention(RetentionPolicy.RUNTIME)public @interface TestAnnotations { TestAnnotation[] value();}@Repeatable(TestAnnotations.class)@Retention(RetentionPolicy.RUNTIME)@Documented@Target({ElementType.TYPE, ElementType.METHOD})public @interface TestAnnotation { String value() default \"\";}@TestAnnotation(value = \"a\")@TestAnnotation(value = \"b\")public class User { } 注解属性在自定义的注解里面添加属性 1234public @interface TestAnnotation { String value() default \"\";} 这里需要注意的是属性为value时，在使用时可以省略name值，写成@TestAnnotation(“a”) 注解的提取这里演示被Repeatable修饰后的注解的提取 12345678910public void test() { boolean b = User.class.isAnnotationPresent(TestAnnotations.class); if (b) { TestAnnotations testAnnotations = User.class.getAnnotation(TestAnnotations.class); TestAnnotation[] annotations = testAnnotations.value(); for (TestAnnotation t : annotations) { System.out.println(t.value()); } }} 用法注解就像一个记号一样，思考你的代码在哪些地方需要做一下标记，标记完后再找到具有这些标记的地方，完成业务的处理？ 参考1. Java 注解 （Annotation）你可以这样学","link":"/2019/06/12/Java注解知识整理/"},{"title":"Jenkins集成Helm进行应用持续发布","text":"目标 在开发过程中，对开发的应用版本进行持续迭代并且发布到kubernetes集群中 使用Helm工具以chart升级的方式完成不同版本应用的发布升级 前提 在使用Helm之前，已经完成了Jenkins的部署，并且已经正常运行脚本与Kubernetes平台进行 通过kubectl命令执行配置文件完成应用的版本更新 实现步骤 helm chart制作，此步骤略 包含helm工具的jenkins容器镜像制作 制作完成的镜像文件 harbor.3incloud.com/library/jenkins-jnlp:latest 初始化应用安装 helm init --client-only &amp;&amp; helm repo add --username jenkins --password password myharbor https://harbor.3incloud.com/chartrepo/XXXX &amp;&amp; helm repo update 这里主要就是在slave中初始化helm，并且添加私有的chart仓库 Jenkins完成应用持续部署 helm upgrade --reuse-values --set-string image.tag='${build_tag}' deploy-name --version 0.1.0 myharbor/chart-name 通过重新设定chart的image.tag完成容器的版本升级，--reuse-values 表示在原本参数的基础上进行更新 完整的Pipeline脚本123456789101112131415161718192021222324252627node('worker') { stage('Clone') { echo \"1.Clone Stage\" git credentialsId: 'gitlab-auth', url: 'https://gitlab.3incloud.com/xxx/xxx-server.git' script { build_tag = sh(returnStdout: true, script: 'git rev-parse --short HEAD').trim() } } stage('Test') { echo \"2.Test Stage\" } stage('Build') { echo \"3.Build Docker Image Stage\" sh \"docker build -t harbor.3incloud.com/xxx/xxx-server:${build_tag} .\" } stage('Push') { echo \"4.Push Docker Image Stage\" withDockerRegistry(credentialsId: 'harbor-ci', url: 'https://harbor.3incloud.com') { sh \"docker push harbor.3incloud.com/xxx/xxx-server:${build_tag}\" } } stage('Deploy') { echo \"5. Deploy Stage\" sh \"helm init --client-only &amp;&amp; helm repo add --username jenkins --password password myharbor https://harbor.3incloud.com/chartrepo/xxx &amp;&amp; helm repo update\" sh \"helm upgrade --reuse-values --set-string image.tag='${build_tag}' avic-server --version 0.1.0 myharbor/xxx-server\" }}","link":"/2019/04/25/Jenkins集成Helm进行应用持续发布/"},{"title":"Optional是这样用吗?","text":"如果你写的Java代码中还包含了对Null的判断，咦，是不是有点low了。本节主要包含了对JDKjava.util.Optional的理解。 使用Optional需要理解这几点精髓: 创建Optional对象创建一个空对象12345678910111213/** * Returns an empty {@code Optional} instance. No value is present for this * Optional. * * @apiNote Though it may be tempting to do so, avoid testing if an object * is empty by comparing with {@code ==} against instances returned by * {@code Option.empty()}. There is no guarantee that it is a singleton. * Instead, use {@link #isPresent()}. * * @param &lt;T&gt; Type of the non-existent value * @return an empty {@code Optional} */public static&lt;T&gt; Optional&lt;T&gt; empty() 这没什么好说的。 创建一个非空对象123456789/** * Returns an {@code Optional} with the specified present non-null value. * * @param &lt;T&gt; the class of the value * @param value the value to be present, which must be non-null * @return an {@code Optional} with the value present * @throws NullPointerException if value is null */public static &lt;T&gt; Optional&lt;T&gt; of(T value) 需要注意的是参数value值不可以为空，否则会在运行期抛出NullPointerException 创建一个可以为空的对象12345678910/** * Returns an {@code Optional} describing the specified value, if non-null, * otherwise returns an empty {@code Optional}. * * @param &lt;T&gt; the class of the value * @param value the possibly-null value to describe * @return an {@code Optional} with a present value if the specified value * is non-null, otherwise an empty {@code Optional} */public static &lt;T&gt; Optional&lt;T&gt; ofNullable(T value) 这个就比较好用了，管你是空还是非空，都到碗里来。 对象转换(业务处理)熟悉Java8相关Function的很容易理解 对Optional数据进行消费1public void ifPresent(Consumer&lt;? super T&gt; consumer) 参数为一个Consumer函数，你懂的 对Optional数据进行转换123public&lt;U&gt; Optional&lt;U&gt; map(Function&lt;? super T, ? extends U&gt; mapper)public&lt;U&gt; Optional&lt;U&gt; flatMap(Function&lt;? super T, Optional&lt;U&gt;&gt; mapper) 参数是一个Function函数，两者的区别在于转换结果对象不一样。 对Optional数据进行过滤1public Optional&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate) 参数是一个Predicate函数 获取值补偿输出意思是如果当前Optional的值不为空则直接返回该值，如果该值为空，则返回另外一个值。Optional类提供了2个函数 123public T orElse(T other);public T orElseGet(Supplier&lt;? extends T&gt; other) 区别在于，orElse()接收一个参数作为返回，而orElseGet则是接收一个Supplier生产函数。 抛出异常很多时候，我们对于Null业务的处理是抛出一个自定义异常。 1public &lt;X extends Throwable&gt; T orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier) throws X; 参数是一个生产函数 Example不使用Optional的写法 12345678public void test() { String name = getNameById(0); if (name!=null) { name = name.toUpperCase(); } else { throw new NullPointerException(); }} 使用Optional后，Null只在你心里 123456@Testpublic void test() { Optional&lt;String&gt; v = Optional.ofNullable(getNameById(0)); String name = v.map(String::toUpperCase) .orElseThrow(NullPointerException::new);} 总结Optional简单，用法上也就上面提到的3类，对Function的理解是关键。","link":"/2019/06/10/Optional是这样用吗/"},{"title":"Spring Cloud Config Server","text":"功能 基于rest形式提供额外的配置（键值对或yaml文本） 配置值的加解密（对称或非对称） 与springboot集成简单 环境仓库你的配置数据应该存放在哪里？Spring Cloud Config提供了多种策略，比如可以是filesystem，git，vault等，这里我们使用git管理我们的配置数据 Config Server如何做到管理应用的多个环节配置呢，它主要是用了以下三个变量来对配置数据进行区分 {application} 对应到客户端的spring.application.name {profile} 对应到客户端spring.application.profile {label} 这是服务端标记版本化的配置文件集合 这样客户端spring boot应用在启动的时候通过指定应用启动的参数，从而获取对应的配置数据 一个客户端应用程序引导配置示例 12345spring: application: name: foo profiles: active: dev，mysql 使用git作为存储库的一些配置 123456789101112spring: cloud: config: server: git: uri: https：//example.com/my/{application} # 占位符 skipSslValidation: true # 跳过ssl证书验证，默认false timeout: 4 # 超时时间（秒） username: user password: pw # 配置认证 searchPaths: '{application}' # 带占位符的搜索路径 refreshRate: 0 # 刷新频率，0表示每次请求都会获取最新的配置 健康指标Config Server附带一个运行状况指示器，用于检查配置EnvironmentRepository是否正常，默认情况下指示器请求的{application}是app，{profile}是default 配置健康指示器 1234567891011spring: cloud: config: server: health: repositories: myservice: label: mylabel myservice-dev: name: myservice profiles: development 如果想要禁用健康检查需要设置 spring.cloud.config.server.health.enabled=false 另外在配置健康检查之后，如果需要获取详细的健康指标数据还需要做额外的配置 12345678management: endpoints: enabled-by-default: true web: base-path: /admin endpoint: health: show-details: always # 显示详细数据 安全通过集成spring-boot-starter-security使用默认的HTTP Basic来保护配置数据 配置用户名密码 12345spring: security: user: name: yuexin password: XXX 加密与解密不想看了，用的时候再去看文档 附上完整的配置 123456789101112131415161718192021222324252627282930spring: application: name: clivia-config-server cloud: config: server: git: uri: https://github.com/yuexine/cloud-repo.git username: yuexine password: XXX search-paths: clivia health: repositories: cloud-repo: name: foo profiles: dev security: user: name: yuexin password: XXXserver: port: 8888management: endpoints: enabled-by-default: true web: base-path: /admin endpoint: health: show-details: always 参考: 官方文档-基于版本2.1.0.RELEASE Spring cloud config Actuator健康监测","link":"/2019/05/06/Spring-Cloud-Config-Server/"},{"title":"Spring Cloud Eureka Client","text":"使用Eureka Client 在pom中包含jar 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 注册指定注册中心的位置 1234eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 注册认证HTTP Basic认证已经自动添加到eureka客户端中, 更复杂的需求，参考文档实现 1http://user:password@localhost:8761/eureka 源码分析在阅读源码的时候，我们根据它本身提供的功能去关注它实现的过程，以及代码是怎么被触发的 入口 通过观察spring-cloud-netflix-eureka-client包中的META-INF/spring.factories可以看到里面配置了一组EnableAutoConfiguration, 我们重点关注EurekaClientAutoConfiguration EurekaClientAutoConfiguration 在这个对象中，主要是根据条件创建了一组spring bean, 包括 EurekaClientConfigBean ManagementMetadataProvider EurekaInstanceConfigBean DiscoveryClient EurekaServiceRegistry EurekaClient EurekaClient 继续跟踪代码，观察EurekaClient的初始化过程 1234567891011121314 public class CloudEurekaClient extends DiscoveryClient { ... public CloudEurekaClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs&lt;?&gt; args, ApplicationEventPublisher publisher) { super(applicationInfoManager, config, args); this.applicationInfoManager = applicationInfoManager; this.publisher = publisher; this.eurekaTransportField = ReflectionUtils.findField(DiscoveryClient.class, \"eurekaTransport\"); ReflectionUtils.makeAccessible(this.eurekaTransportField); } ...} 这里会调用父级的构造方法去执行注册、心跳、缓存刷新等任务 1234567891011121314151617181920212223242526272829 DiscoveryClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args, Provider&lt;BackupRegistry&gt; backupRegistryProvider) { ... // default size of 2 - 1 each for heartbeat and cacheRefresh scheduler = Executors.newScheduledThreadPool(2, new ThreadFactoryBuilder() .setNameFormat(\"DiscoveryClient-%d\") .setDaemon(true) .build()); heartbeatExecutor = new ThreadPoolExecutor( 1, clientConfig.getHeartbeatExecutorThreadPoolSize(), 0, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), new ThreadFactoryBuilder() .setNameFormat(\"DiscoveryClient-HeartbeatExecutor-%d\") .setDaemon(true) .build() ); // use direct handoff cacheRefreshExecutor = new ThreadPoolExecutor( 1, clientConfig.getCacheRefreshExecutorThreadPoolSize(), 0, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), new ThreadFactoryBuilder() .setNameFormat(\"DiscoveryClient-CacheRefreshExecutor-%d\") .setDaemon(true) .build() ); // use direct handoff ... } 到这里我们可以发现，spring cloud eureka client将这些任务都委托给了Netflix的Eureka组建去执行","link":"/2019/05/08/Spring-Cloud-Eureka-Client/"},{"title":"Spring Cloud Eureka Server","text":"运行Eureka Server 将Eureka Server集成到应用中，只需要在pom中加入 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 接着在启动类上加入@EnableEurekaServer 最后配置application.yml 1234567891011server: port: 8761eureka: instance: hostname: localhost client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 高可用在生产环境下，往往会部署多个eureka实例，使它们相互注册，实现的方式是通过修改配置实现 12345678910111213141516171819---spring: profiles: peer1eureka: instance: hostname: peer1 client: serviceUrl: defaultZone: http://peer2/eureka/---spring: profiles: peer2eureka: instance: hostname: peer2 client: serviceUrl: defaultZone: http://peer1/eureka/ 这样客户端在使用的时候，在指定注册中心时，指定多个，用逗号隔开 1234eureka: client: serviceUrl: defaultZone: http://peer1/eureka/,http://peer2/eureka 安全的 Eureka Server通过加入spring-boot-starter-security，使服务的注册与发现操作开启认证。 禁用CSRF 123456789@EnableWebSecurityclass WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().ignoringAntMatchers(\"/eureka/**\"); super.configure(http); }} 在配置中加入 12345spring: security: user: name: admin password: pwd 修改defaultZone，指定name&amp;password，这里需要注意的是，所有的配置defaultZone的地方都需要配置name&amp;password，包括Eureka Server本身 123456789eureka: instance: hostname: localhost prefer-ip-address: true # 这里使用ip而不是默认的hostname client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://admin:pwd@${eureka.instance.hostname}:${server.port}/eureka/","link":"/2019/05/09/Spring-Cloud-Eureka-Server/"},{"title":"Spring Cloud OpenFeign","text":"理解OpenFeign它声明一个REST客户端，来完成远程服务的调用，Feign会动态实现由JAX-RS或Spring MVC注解修饰的接口，主要用途是用来简化服务之间的相互调用 在SpringBoot中集成Feign前提已经准备好由SpringBoot构建的客户端和服务端，并且已经成功注册到Eureka注册中心。 引入相关jar在客户端中Pom中加入 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 相关配置在客户端启动类上加上注解@EnableFeignClients 使用声明一个接口，在接口的方法上引入SpringMvc的注解，即可完成远程服务的调用 123456@FeignClient(name = \"clivia-service-notification-${spring.profiles.active}\")public interface NotificationClient { @RequestMapping(method = RequestMethod.GET, value = \"/\") String home();} 使用Feign使用OKHTTP前面在引入jar包的时候，已经集成了okhttp相关的包 在理解这一块内容的时候，简单看了一下这一块的实现，根据官方的文档介绍 Spring Cloud Netflix提供了一些Bean，包括了Feign Client，在Ribbon开启的情况下，默认的FeignClient是LoadBalancerFeignClient 跟踪LoadBalancerFeignClient代码，它在构造器上定义了一个委派的Client,继续看这个对象。他的实现在接口内，并且最终使用的是HttpURLConnection, 也就是Java原生的远程连接对象。 回到主题，在这个包中，有一个配置类对象OkHttpFeignLoadBalancedConfiguration，开启条件是feign.okhttp.enabled=true，并且OkHttpClient存在于classpath中 继续观察当前对象 123456789101112131415161718192021222324252627282930313233343536373839404142@Configuration@ConditionalOnMissingBean(okhttp3.OkHttpClient.class)protected static class OkHttpFeignConfiguration { private okhttp3.OkHttpClient okHttpClient; &lt;!--定义了一个连接池--&gt; @Bean @ConditionalOnMissingBean(ConnectionPool.class) public ConnectionPool httpClientConnectionPool( FeignHttpClientProperties httpClientProperties, OkHttpClientConnectionPoolFactory connectionPoolFactory) { Integer maxTotalConnections = httpClientProperties.getMaxConnections(); Long timeToLive = httpClientProperties.getTimeToLive(); TimeUnit ttlUnit = httpClientProperties.getTimeToLiveUnit(); return connectionPoolFactory.create(maxTotalConnections, timeToLive, ttlUnit); } &lt;!--创建了一个OkHttpClient客户端--&gt; @Bean public okhttp3.OkHttpClient client(OkHttpClientFactory httpClientFactory, ConnectionPool connectionPool, FeignHttpClientProperties httpClientProperties) { Boolean followRedirects = httpClientProperties.isFollowRedirects(); Integer connectTimeout = httpClientProperties.getConnectionTimeout(); this.okHttpClient = httpClientFactory .createBuilder(httpClientProperties.isDisableSslValidation()) .connectTimeout(connectTimeout, TimeUnit.MILLISECONDS) .followRedirects(followRedirects).connectionPool(connectionPool) .build(); return this.okHttpClient; } @PreDestroy public void destroy() { if (this.okHttpClient != null) { this.okHttpClient.dispatcher().executorService().shutdown(); this.okHttpClient.connectionPool().evictAll(); } } } 通过对以上代码的理解，我只需要在配置中设置feign.okhttp.enabled=true，即可使用OkHttp作为服务调用的客户端工具，当然，如果在代码中自己配置了OkHttpClientBean，框架本身就不会再重复创建了，相关连接池的配置读取自配置feign.httpclient.* 最后还需要注意的就是设置Feign客户端远程调用的连接和读取的超时时间配置，这个配置需要在客户端中额外配置，默认的配置示例 1234567feign: client: config: default: # 客户端名称，default表示默认 connectTimeout: 6000 readTimeout: 6000 # 表示6s loggerLevel: basic 通过修改OKHttp连接池和请求相应相关的参数来获取更好的性能 日志配置Feign日志记录仅响应DEBUG级别日志，所以首先配置Feign Client的日志级别为DEBUG 123logging: level: com.vcors.project.common.feign.NotificationClient: DEBUG 接下来配置Logger.Level，这里可以单独为每个客户端配置，也可以统一配置，下面的示例是配置到一个class中 123456789@Configurationpublic class FooConfiguration { @Bean Logger.Level feignLoggerLevel() { return Logger.Level.FULL; }}@FeignClient(name = \"clivia-service-notification-${spring.profiles.active}\", configuration = {DefaultFeignConfiguration.class}) 日志级别 None 无日志，默认 BASIC 记录请求URL和方法及响应时间和状态 HEADERS 记录基本信息及请求响应头 FULL 记录全部的信息 数据压缩通过GZIP压缩请求 1234567feign: compression: request: enabled: true min-request-size: 2048 response: enabled: true HTTP BASIC认证对服务的API增加访问保护，是非常有意义的，被请求的服务通过集成spring-boot-starter-security, 可以快速使用HTTP BASIC 这个时候Feign在调用远程服务的时候，通过加入拦截器，可以完成HTTP BASIC的验证 12345678910111213141516171819@Configurationpublic class DefaultFeignConfiguration { @Bean Logger.Level feignLoggerLevel() { return Logger.Level.BASIC; } &lt;!--请求重试--&gt; @Bean Retryer feignRetryer() { return Retryer.NEVER_RETRY; } @Bean public BasicAuthRequestInterceptor basicAuthRequestInterceptor() { return new BasicAuthRequestInterceptor(\"admin\", \"passwd\"); }}","link":"/2019/05/09/Spring-Cloud-OpenFeign/"},{"title":"Spring WebFlux源码学习笔记(二)","text":"继续前面的学习 先看看WebHandler从前面的过程中我们知道，HttpHandler将Request请求最后交给了WebHandler去处理，我们先简单学习一下WebHandler的实现类 WebHandler实现类在WebHandler的实现类里面包含了一个装饰器对象WebHandlerDecorator，HttpWebHandlerAdapter也是继承自它 ExceptionHandlingWebHandlerWebHandler装饰器调用一个或多个WebExceptionHandlers处理webHandle过程中的错误 1234567891011121314151617@Overridepublic Mono&lt;Void&gt; handle(ServerWebExchange exchange) { Mono&lt;Void&gt; completion; try { completion = super.handle(exchange); //1 } catch (Throwable ex) { completion = Mono.error(ex); } for (WebExceptionHandler handler : this.exceptionHandlers) { completion = completion.onErrorResume(ex -&gt; handler.handle(exchange, ex)); //2 } return completion;} 调用父级的去处理请求 发生异常后进行异常解析 FilteringWebHandlerFilteringWebHandler使用一个WebFilterChain去处理ServerWebExchange 1private final DefaultWebFilterChain chain; 123456@Overridepublic Mono&lt;Void&gt; filter(ServerWebExchange exchange) { return Mono.defer(() -&gt; this.currentFilter != null &amp;&amp; this.next != null ? this.currentFilter.filter(exchange, this.next) : this.handler.handle(exchange)); 这里的handle实际上是DispatcherHandler DispatcherHandlerDispatcherHandler应该是WebFlux核心的对象，在这里完成了对请求的处理。 123456789101112@Overridepublic Mono&lt;Void&gt; handle(ServerWebExchange exchange) { if (this.handlerMappings == null) { return createNotFoundError(); } return Flux.fromIterable(this.handlerMappings) //1 .concatMap(mapping -&gt; mapping.getHandler(exchange)) //2 .next() //3 .switchIfEmpty(createNotFoundError()) //4 .flatMap(handler -&gt; invokeHandler(exchange, handler)) //5 .flatMap(result -&gt; handleResult(exchange, result)); //6} 将handlerMappings打包成一个广播对象 使用concatMap操作符收集mapping.getHandler(exchange)返回的对象。具体Handle过程我们后面再看。 next()取出第一个对象 如果没有找到映射函数就广播一个异常Mono 调用业务代码函数处理请求 对业务代码结果进行处理 从WebHandlerDecorator开始SpringWebFlux是怎么将这个过程串起来的呢？ 首先，HttpWebHandlerAdapter将请求委派给 ExceptionHandlingWebHandler，ExceptionHandlingWebHandler收集并处理过程中的异常，它使用FilteringWebHandler来处理ServerWebExchange。 FilteringWebHandler本身也不处理ServerWebExchange，继续将任务交给了DispatcherHandler去执行。","link":"/2019/05/22/Spring-WebFlux源码学习笔记(二)/"},{"title":"Spring WebFlux源码学习笔记(一)","text":"在开始学习WebFlux之前，需要对Java的函数式编程有一定的了解，熟悉相关函数式接口的用法，包括Function，BiFunction等 开始学习开始，我们需要找一个切入点，了解一次Http请求发生后，代码响应的过程，这里我们从reactor.netty.http.server的HttpServerHandle开始看起 1234567891011121314151617public void onStateChange(Connection connection, State newState) { if (newState == HttpServerState.REQUEST_RECEIVED) { //1 try { if (log.isDebugEnabled()) { log.debug(format(connection.channel(), \"Handler is being applied: {}\"), handler); } HttpServerOperations ops = (HttpServerOperations) connection; //2 Mono.fromDirect(handler.apply(ops, ops)) .subscribe(ops.disposeSubscriber()); //3 } catch (Throwable t) { log.error(format(connection.channel(), \"\"), t); connection.channel() .close(); } }} 接受一个State为REQUEST_RECEIVED状态的连接 获取在前面的过程中已经将连接信息封装到了HttpServerOperations对象中，这个对象实现了HttpServerRequest, HttpServerResponse 12 class HttpServerOperations extends HttpOperations&lt;HttpServerRequest, HttpServerResponse&gt;implements HttpServerRequest, HttpServerResponse 创建了一个Mono对象(Reactor中的用来发出一个元素)，并且订阅(触发)了这个Publisher。 备注: Mono.fromDirect() 用来转换一个Publisher到Mono免去了一些基础的验证。 处理适配器:ReactorHttpHandlerAdapter从开始的过程第3步中使用了ReactorHttpHandlerAdapter对HttpServerRequest, HttpServerResponse进行了处理 1public class ReactorHttpHandlerAdapter implements BiFunction&lt;HttpServerRequest, HttpServerResponse, Mono&lt;Void&gt;&gt; ReactorHttpHandlerAdapter实现了BiFunction，函数方法接收2个参数，分别是HttpServerRequest, HttpServerResponse，返回Mono，看类名可以看出这是一个适配器对象，实际的Handler为 12345678910111213141516171819202122public Mono&lt;Void&gt; apply(HttpServerRequest reactorRequest, HttpServerResponse reactorResponse) { NettyDataBufferFactory bufferFactory = new NettyDataBufferFactory(reactorResponse.alloc()); try { ReactorServerHttpRequest request = new ReactorServerHttpRequest(reactorRequest, bufferFactory); //1 ServerHttpResponse response = new ReactorServerHttpResponse(reactorResponse, bufferFactory); //2 if (request.getMethod() == HttpMethod.HEAD) { response = new HttpHeadResponseDecorator(response); } return this.httpHandler.handle(request, response) //3 .doOnError(ex -&gt; logger.trace(request.getLogPrefix() + \"Failed to complete: \" + ex.getMessage())) //4 .doOnSuccess(aVoid -&gt; logger.trace(request.getLogPrefix() + \"Handling completed\")); //5 } catch (URISyntaxException ex) { if (logger.isDebugEnabled()) { logger.debug(\"Failed to get request URI: \" + ex.getMessage()); } reactorResponse.status(HttpResponseStatus.BAD_REQUEST); return Mono.empty(); }} 包装HttpServerRequest到ReactorServerHttpRequest 包装HttpServerResponse到ReactorServerHttpResponse 调用ReactiveWebServerApplicationContext的内部类ServerManager完成handle。 出错时打印错误日志 成功是打印成功日志 注： doOnError()和doOnSuccess()不会对序列造成改变 继续任务委派在ServerManager里面包含了HttpHandler对象，实际的实现对象为HttpWebHandlerAdapter 12345678910111213141516@Overridepublic Mono&lt;Void&gt; handle(ServerHttpRequest request, ServerHttpResponse response) { if (this.forwardedHeaderTransformer != null) { request = this.forwardedHeaderTransformer.apply(request); } ServerWebExchange exchange = createExchange(request, response); //1 LogFormatUtils.traceDebug(logger, traceOn -&gt; exchange.getLogPrefix() + formatRequest(exchange.getRequest()) + (traceOn ? \", headers=\" + formatHeaders(exchange.getRequest().getHeaders()) : \"\")); return getDelegate().handle(exchange) //2 .doOnSuccess(aVoid -&gt; logResponse(exchange)) //3 .onErrorResume(ex -&gt; handleUnresolvedError(exchange, ex)) //4 .then(Mono.defer(response::setComplete)); //5} 将request和response组合成了一个对象ServerWebExchange 调用被委派对象处理这个组合后的对象 执行成功后打印response日志 捕获handle过程中的异常，处理后返回一个Mono对象 用 Mono 来表示序列已经结束 1234@Overridepublic Mono&lt;Void&gt; setComplete() { return !isCommitted() ? doCommit(null) : Mono.empty(); //6} 12345678910111213141516171819202122protected Mono&lt;Void&gt; doCommit(@Nullable Supplier&lt;? extends Mono&lt;Void&gt;&gt; writeAction) { if (!this.state.compareAndSet(State.NEW, State.COMMITTING)) { return Mono.empty(); } this.commitActions.add(() -&gt; Mono.fromRunnable(() -&gt; { applyStatusCode(); applyHeaders(); applyCookies(); this.state.set(State.COMMITTED); })); //7 if (writeAction != null) { this.commitActions.add(writeAction); } List&lt;? extends Mono&lt;Void&gt;&gt; actions = this.commitActions.stream() .map(Supplier::get).collect(Collectors.toList()); //8 return Flux.concat(actions).then(); //9} 设置处理完成，提交了一个空的writeAction 添加响应状态码，响应头，cookie等 转换为一个类型Mono的数组 将3步骤产生的数组用打包成一个Mono返回 小结从过程上看，当收到一个Http请求后，首先交给HttpHandlerAdapter类去处理，经过对数据的一些组合和处理，然后将请求丢给HttpWebHandlerAdapter去处理，从设计上看，WebHandler只是HttpHandler的一个子集，HttpWebHandlerAdapter本身是一个适配器对象，它会将任务继续委派给FilteringWebHandler","link":"/2019/05/21/Spring-WebFlux源码学习笔记(一)/"},{"title":"TCP与UDP","text":"传输层的作用作为传输层的两个主要协议，为了识别自己传输的数据属于哪个应用，在协议内设定了端口号 将接收和发送的数据与特定的应用程序进行关联起来,通过socket，也就是绑定了端口 区别 TCP 是面向连接的，可靠的的流协议，它提供了可靠性传输，实行顺序控制`重发控制流量控制拥塞控制提高网络利用率`等多种功能 UDP 是不具有可靠性的数据报协议，细微的处理交给上层的应用去完成 TCP头部就不解释每个字段的意思了 TCP的特点通过序列号和确认应答提高可靠性 数据包丢失 数据无法到达 数据应答丢失 重发的超时时间如何确定在BSD的Unix以及Windows系统中，超时都是以0.5s为单位进行控制的，因此重发超时的都是0.5的整数倍，不过由于最初的数据包还不知道往返时间，所以其重发的超时一般设置在6s左右。 连接管理这个会经常提到 TCP以段发送数据在建立TCP连接的同时，也可以确定发送数据包的单位，称为最大消息长度（MSS），TCP在传送大量数据时，是以MSS的大小将数据进行分割发送。 利用窗口控制提高速度TCP以1个段为单位，每发一个段进行一次确认应答，性能太差了，为了解决这个问题。 确认应答不再是以每个分段，而是以更大的单位进行确认，转发的时间被大幅度缩短。也就是说，发送端主机，在发送了一个段以后不必要一直等待确认应答，而是继续发送 窗口控制与重发控制 流控制为了防止流量浪费，比如说，数据接收端在高负荷的情况下无法接受任何数据。如果将本来接受的数据丢弃，则会触发重发机制。 为了防止这种现象，TCP提供了一种机制可以让发送端根据接收端的实际接受能力控制发送的数据量。这就是流控制。 做法就是在TCP首部中，有一个字段来通知窗口的大小，值越大，吞吐量越高 拥塞控制慢启动，慢慢变快 捎带应答 UDP头部","link":"/2019/05/08/TCP与UDP/"},{"title":"《亿级流量网站架构核心技术》读书笔记","text":"总体感受这个书印刷的墨有点臭，强忍着在看，从这一点体验，特别不好。 思维导图 内容待完善","link":"/2019/06/01/《亿级流量网站架构核心技术》读书笔记/"},{"title":"Vim资料整理","text":"vim命令速查 MacVim下载 Vim文档中文翻译","link":"/2019/05/24/Vim资料整理/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2019/04/24/hello-world/"},{"title":"gRPC 入门学习","text":"功能gRPC是Google公司开源的一个远程服务调用框架，基于HTTP2协议。 特点 通过接口定义语言(IDL)定义了客户端与服务端数据交换的格式，该文件的扩展名为.proto, 通过将文件编译到对应的开发语言来完成系统的集成。 gRPC使用高效的序列化工具Protocol buffer 在SpringBoot中使用gRPC完成服务间调用完整的代码地址 方法及参数对象声明首先我们需要声明服务调用的接口方法与参数，推荐使用proto3，通过在pom中使用protobuf-maven-plugin插件，可以在编译的时候将.proto文件生成java class文件。 1234567891011121314151617syntax = \"proto3\";option java_multiple_files = true;package com.vcors.demo.grpcproto;message Person { string first_name = 1; string last_name = 2;}message Greeting { string message = 1;}service HelloWorldService { rpc sayHello (Person) returns (Greeting);} 服务端开发理解.proto代码生成 对于.proto文件中定义的对象，会生成对应的JavaClass，这是可以通过Protocal Buffers序列化的对象模型 对于.proto文件中定义的方法，会生成XXXGrpc XXXGrpc 接口方法声明 1public static abstract class HelloWorldServiceImplBase implements io.grpc.BindableService {} 这个抽象内部类主要用来集成在服务端，作为方法实现的父级接口 方法存根 种类分为 XXXBlockingStub blocking-style stub that supports unary and streaming output calls on the service XXXFutureStub ListenableFuture-style stub that supports unary calls on the service XXXStub async stub that supports all call types for the service 方法存根用来集成到客户端，方法客户端调用在服务端实现的方法。 集成依赖在服务端中集成proto模块声明的模型和接口方法 12345&lt;dependency&gt; &lt;groupId&gt;com.vcors.demo&lt;/groupId&gt; &lt;artifactId&gt;grpc-proto&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 方法实现通过继承HelloWorldServiceGrpc.HelloWorldServiceImplBase来重写.proto接口中声明的方法，也就是具体业务需要实现的逻辑代码都在这 12345678910111213141516171819@GRpcServicepublic class HelloWorldServiceImpl extends HelloWorldServiceGrpc.HelloWorldServiceImplBase { private static final Logger LOGGER = LoggerFactory.getLogger(HelloWorldServiceImpl.class); @Override public void sayHello(Person request, StreamObserver&lt;Greeting&gt; responseObserver) { LOGGER.info(\"server received {}\", request); String message = \"Hello \" + request.getFirstName() + \" \" + request.getLastName() + \"!\"; Greeting greeting = Greeting.newBuilder().setMessage(message).build(); LOGGER.info(\"server responded {}\", greeting); responseObserver.onNext(greeting); responseObserver.onCompleted(); } 客户端调用服务端创建存根接口首先在客户端中也同样要在pom中集成proto声明模块 创建存根方法对象 1234ManagedChannel managedChannel = ManagedChannelBuilder .forAddress(\"localhost\", 6565).usePlaintext().build(); helloWorldServiceBlockingStub = HelloWorldServiceGrpc.newBlockingStub(managedChannel); 执行方法调用像调用本地方法一样，实现不同应用接口的调用 12Greeting greeting = helloWorldServiceBlockingStub.sayHello(person); 测试同时启动服务端与客户端应用，调用客户端接口来收到服务端的正确响应 理解gRPC-spring-boot-startergRPC-spring-boot-starter 是对GRpcServer的一个封装，可以使我们在spring-boot项目中更简单的使用GRpc，核心功能就是启动了GRpcServer，并将通过@GRpcServer注解的Service注册到Server中 理解GRpcAutoConfiguration在grpc-spring-boot-starter/META-INF/spring.factories配置了GRpcAutoConfiguration, springboot启动时会自动加载该配置文件 该文件主要初始化了以下几个Bean实例 GRpcServerRunner HealthStatusManager GRpcServerBuilderConfigurer 理解GRpcServerRunner启动一个GRpc Server, 集成到SpringBoot中后，项目无需再集成其他的web server 123456789101112131415161718192021222324252627public void run(String... args) throws Exception { log.info(\"Starting gRPC Server ...\"); Collection&lt;ServerInterceptor&gt; globalInterceptors = (Collection)this.getBeanNamesByTypeWithAnnotation(GRpcGlobalInterceptor.class, ServerInterceptor.class).map((name) -&gt; { return (ServerInterceptor)this.applicationContext.getBeanFactory().getBean(name, ServerInterceptor.class); }).collect(Collectors.toList()); this.serverBuilder.addService(this.healthStatusManager.getHealthService()); this.getBeanNamesByTypeWithAnnotation(GRpcService.class, BindableService.class).forEach((name) -&gt; { BindableService srv = (BindableService)this.applicationContext.getBeanFactory().getBean(name, BindableService.class); ServerServiceDefinition serviceDefinition = srv.bindService(); GRpcService gRpcServiceAnn = (GRpcService)this.applicationContext.findAnnotationOnBean(name, GRpcService.class); serviceDefinition = this.bindInterceptors(serviceDefinition, gRpcServiceAnn, globalInterceptors); this.serverBuilder.addService(serviceDefinition); String serviceName = serviceDefinition.getServiceDescriptor().getName(); this.healthStatusManager.setStatus(serviceName, ServingStatus.SERVING); log.info(\"'{}' service has been registered.\", srv.getClass().getName()); }); if (this.gRpcServerProperties.isEnableReflection()) { this.serverBuilder.addService(ProtoReflectionService.newInstance()); log.info(\"'{}' service has been registered.\", ProtoReflectionService.class.getName()); } this.configurer.configure(this.serverBuilder); this.server = this.serverBuilder.build().start(); this.applicationContext.publishEvent(new GRpcServerInitializedEvent(this.server)); log.info(\"gRPC Server started, listening on port {}.\", this.server.getPort()); this.startDaemonAwaitThread();} 理解@GRpcService通过该注解声明的方法会被声明为Spring Bean，本质上它是一个@Service注解，另外就是在启动GRpcServer时会注册该Bean。 Next 接口调用的认证处理 结合Kubernetes平台实现服务发现与负载均衡","link":"/2019/05/17/gRPC-入门学习/"},{"title":"体验Travis-ci","text":"Travis-ci是一个持续集成工具，作用和Jenkins类似，在Github上很多开源项目都用它来集成, 如Google仓库的集成 入门配置 使用github账号登录到 Travis-CI 选择需要集成的项目，激活 在项目中编写 .travis.yml 文件告诉Travis 该做什么 以 waffle 为例，这是一个java项目 123language: javajdk: - oraclejdk8 提交并push配置文件，以触发Travis CI构建 通过构建命令的返回状态，我们访问 Travis CI 查看构建通过或者失败 配置通知文档 默认通知设置默认情况下，电子邮件会通知代码提交者 更改通知频率 你可以通配置 on_success on_failure 来更改通知频率 always: 总是发送通知 never: 从来不发送通知 change: 在构建状态改变时发送通知 配置邮件通知可以指定通知人通过email设置项 关闭email通知： 12notifications: email: false 配置示例 123456789notifications: email: recipients: - one@example.com - other@example.com on_success: never on_failure: always slack: on_success: always Slack 通知配置Travis CI 可以向你的Slack Channel 发送关于构建结果的通知。 在Slack上，建立一个新的Travis CI集成 将已经包含正确标记的设置复制并粘贴到.travis.yml，然后您就可以开始使用了。 token 加密（可选） 加密工具安装方法 安装成功后在项目目录下执行 1travis encrypt \"&lt;account&gt;:&lt;token&gt;#channel\" --add notifications.slack.rooms 配置 简单配置 12notifications: slack: '&lt;account&gt;:&lt;token&gt;#development' 指定多个channel 1234567notifications: slack: rooms: - &lt;account&gt;:&lt;token&gt;#development - &lt;account&gt;:&lt;token&gt;#general on_success: change # default: always on_failure: always # default: always 如果是加密的 12345notifications: slack: rooms: - secure: \"sdfusdhfsdofguhdfgubdsifgudfbgs3453durghssecurestringidsuag34522irueg=\" on_success: always 设置好后，每次提交，就会收到类似以下截图 嵌入状态图标你可以将现实构建状态的图像（也称为徽章或图标）嵌入到文件或者网站中 点击右上角的状态图片打开一个对话框，其中包含markdown，html等状态图片的模版 在对话框中选择分支和模版 复制文本并将其粘贴到你自己的文件或者网站上。构建状态图像可以在Travis CI上公开获取","link":"/2019/06/13/体验Travis-ci/"},{"title":"把玩OpenShift系列(一)","text":"OpenShift 是什么？我才懒得告诉你。 本节主要包含的内容是在OpenStack虚拟机上搭建OpenShift社区版okd(v3.11) 安装计划由于是从0开始学习OpenShift的使用，所以部署的集群不包含高可用部分，部署的目的是体验一下OpenShift的功能。 系统与环境需要硬件需求这没什么好说的，配置尽量高就对了，别跟我提最低的配置，我不想听。我是不会在电脑上跑虚拟机的。 软件要求操作系统我使用的是centos7.5，貌似OpenShift非社区版只能购买Redhat的商业操作系统才支持，滋滋。 需要注意官方文档上提到了这个集群需要一个DNS服务器，我折腾了半天，不会搭DNS服务器，这一块我就暂时放弃了，后面再研究这个，然后用的方案是修改hosts配合dnsmasq来实现。 使用的服务器及IP 主机名 IP master.example.com 172.16.26.13 node1.example.com 172.16.26.10 infra-node1.example.com 172.16.26.17 配置Hosts123172.16.26.13 master.example.com172.16.26.10 node1.example.com172.16.26.17 infra-node1.example.com 需要注意的是除了在目标机器上配置Hosts，跳板机上也需要配置，并且配置跳板机(本地电脑)到服务器的免密登录 升级系统内核过程略, 升级内核到最新，这一点官方文档中并没有提到，但是为了担心后面莫名的问题，特意升级到了5.1 安装Docker文档指定了这个版本 1yum install docker-1.13.1 Inventory File准备这个文件是指Ansible的配置文件。 怎么使用Ansible过程略过，在部署前需要对Ansible做入门学习最好。 官方的配置说明 内容有点太多，暂时没有看的欲望。 官方给了一个配置范例 ，按照这个配置稍微做一点修改就可以了。 最终我的配置 123456789101112131415161718192021222324252627282930313233# Create an OSEv3 group that contains the masters, nodes, and etcd groups[OSEv3:children]mastersnodesetcd# Set variables common for all OSEv3 hosts[OSEv3:vars]# SSH user, this user should allow ssh based auth without requiring a passwordansible_ssh_user=root# If ansible_ssh_user is not root, ansible_become must be set to true#ansible_become=trueopenshift_deployment_type=origin# uncomment the following to enable htpasswd authentication; defaults to AllowAllPasswordIdentityProvideropenshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}]# host group for masters[masters]master.example.com# host group for etcd[etcd]master.example.com# host group for nodes, includes region info[nodes]master.example.com openshift_node_group_name='node-config-master'node1.example.com openshift_node_group_name='node-config-compute'infra-node1.example.com openshift_node_group_name='node-config-infra' 下载ansible的部署脚本 1234cd ~/openshift_installgit clone https://github.com/openshift/openshift-ansiblecd openshift-ansiblegit checkout release-3.11 安装安装过程分为2步, 第一步是预检查，第二步是部署，整个过程时间耗时不短，静静等待完成，过程还是很顺利的 1234cd ~/openshift_installansible-playbook [-i /path/to/inventory] playbooks/prerequisites.yml ansible-playbook [-i /path/to/inventory] playbooks/deploy_cluster.yml 验证 验证节点的状态 访问 https://master.openshift.com:8443/console 吐槽一下，页面做的真丑 总结整个部署过程还是比较简单和顺利的，问题是部署完成好像存在一些问题。 疑惑 获取集群信息显示不健康 几个意思？后面有时间再来看这个问题，感觉问题可能出在证书上面。 集群服务ping不通 为什么会有这个疑惑呢？因为对比了k8s集群，svc是可以ping通的 参考1. 官方文档: 红帽软件的文档写的真的好","link":"/2019/06/05/把玩OpenShift系列(一)/"},{"title":"把玩OpenShift系列(二)","text":"本节主要包含的内容是Registry。 Registry: 也就是集成在OpenShift内的一个容器私有仓库，用来存放打包后制作的镜像。 部署Registry在用Ansible搭建平台的时候，已经在infra节点上自动部署了Registry Pod，如果是通过其它的部署方式部署Okd，可能需要手动的部署这个。 访问Registry通过oc命令或者kubectl命令可以看到Registry服务的ip 如何直接访问到这个Registry，文档上是这么描述的 For any direct access, you must have a regular user for your preferred identity provider. A regular user can generate an access token required for logging in to the registry. System users, such as system:admin, cannot obtain access tokens and, therefore, cannot access the registry directly. 我的平台是使用的 HTPASSWD authentication 创建用户 1htpasswd /etc/origin/openshift-htpasswd &lt;user_name&gt; 为这个用户绑定registry读写角色 123oc policy add-role-to-user registry-viewer &lt;user_name&gt;oc policy add-role-to-user registry-editor &lt;user_name&gt; 使用创建的账户进行登录到Okd 1oc login 登录到Registry 1docker login -u openshift -p $(oc whoami -t) &lt;registry_ip&gt;:&lt;port&gt; 需要注意的是，一旦使用这个账号登录到Okd之后，后面所有的命令操作都是以该用户的身份操作，会出现很多命令无权限，再次获得系统管理员身份使用 1oc login -u system:admin 如果docker login成功之后，可以测试一下镜像的push&amp;pull。 在折腾Registry的过程中，并不是很顺利，遇到的问题后面再详细描述。 安全与暴露安全原本我以为通过Ansible安装的Registry不支持Https的，所欲按照文档操作手动配置证书的过程中，发现这部分已经在平台搭建的时候安装好了，所以做了一些无用功 当然可能也还有一点用，就是自带的Https看起来没有提供对Ip的直接登录，手动创建证书时，把ip也带上了，所以后面能通过ip:port直接登录到Registry。 配置细节略过，看文档，非常详细。 暴露其实就是添加了一个路由，比较简单，略过 扩展配置这一部分有一个重点就是镜像文件的存储，默认是用的FileSystem，但在实际生产中，往往会使用其他的存储方案，这一部分后面再研究。 遇到的问题docker无法登录到registry 问题描述 无法通过 docker login 到 registry，提示 TLS handshake timeout 问题分析 由于我使用的是OpenStack虚拟的云主机构建的这个平台，按照以前操作k8s和容器的经验，估计这个和mtu值有关，因为一般的Linux操作系统默认的MTU值是1500，而Openstack云主机mtu值是1450。 解决方法 网上各种搜，各种尝试，解决问题的过程很不爽，最终运气不错，在这里找到了问题的解决方法。 修改 123456# cat /etc/origin/node/node-config.yaml...networkConfig:mtu: 1450networkPluginName: company/openshift-ovs-subnet... 修改mtu到1400 重启 1systemctl restart origin-node.service 重启之后 观察Node节点tun0mtu并没有变化，这算不算一个bug，算了，这样至少问题解决了 对于SDN网络这一块，还不太懂，后面再研究。 Optimizing Network Performance 补充 通过修改系统内文件的配置，发现修改不能生效，继续解决 Modifying Nodes 原来这部分配置已经集成到ConfigMap中了，通过编辑ConfigMap，改完后重启所有节点，ok 123oc get cm -n openshift-node//修改所有的oc edit cm node-config-compute -n openshift-node 参考1. okd官方文档","link":"/2019/06/06/把玩OpenShift系列(二)/"},{"title":"理解ForkJoinPool","text":"前言ForkJoinPool是Java Executor框架的一个实现，它是对于ThreadPoolExecutor的补充，主要使用场景是处理比较大的异步计算任务。 理解为什么适合大的异步任务呢？相对于普通的线程池，维护了一个任务队列，一旦有任务到达，空闲的线程就会从任务队列中弹出一个任务进行处理，如果这个任务执行的时间比较长，那么就不能充分使用线程池里面的其它空闲线程。ForkJoinPool的亮点在于对于一个耗时较长的任务，拆成若干个子任务，并将这些任务提交到多个任务队列中（ForkJoinPool线程池中的每个线程都维护了一个队列），最后将结果合并返回。当然这个任务的拆分并不是由框架完成，需要我们自己的代码中实现。 注意 fork()是提交子任务，join()返回计算结果。这里会阻塞 ForkJoinPool不适用于本身执行耗时短的任务 参考下面这篇博客对ForkJoinPool的介绍比较详细 1. ForkJoinPool入门篇","link":"/2019/05/30/理解ForkJoinPool/"},{"title":"读《黑客与画家》","text":"很不耐烦的把这本书翻了一遍，翻到最后几章的时候，已经慢慢失去了耐心。 我在思考，我花了时间去读这本书，我从中收获到了什么？难道是在看技术书外，再来一些思考，来干扰我的道心，哈哈 看网上很多人对这本书的评价还都不错的样子，可能是我道行不够，不能理解？ 摘录: 黑客真正想做的就是设计优美的软件，考核这种工作是非常困难的。 好玩的软件的需求量，比不上解决客户麻烦问题的软件需求量 如果你犯下与别人一样的错误，那么这个错误不太可能完全来自你自己 如果你想致富，应该怎么做，我认为最好的办法就是自己创业，或者加入创业公司 财富才是你的目标，金钱不是 要致富，你需要两样东西:可测量性和可放大性。你的职位产生的业绩，应该是可测量的…此外，你还必须有可放大性，也就是说你做出的决定能够产生巨大的效应 真正创业之后，你的竞争对手决定你到底要吃多少苦 创业公司不像能经受打击的黑熊，也不像有盔甲的螃蟹，而是像蚊子一样，不带任何防御，就是为达到一个目标而活着 尽快拿出1.0版，根据用户的反映而不是自己的猜测进行软件优化 设计者的品味:好设计是简单的设计；好设计是永不过时的设计；好设计是解决主要问题的设计；好设计是启发性的设计；好设计通常是有点趣味的设计；好设计是艰苦的设计；好设计是看似容易的设计；好设计是对称的设计；好设计是模仿大自然的设计；好设计是一种再设计；好设计是能够复制的设计；好设计通常是奇特的设计；好设计是成批出现的；好设计常常是大胆的设计 如果你长期使用某种语言，你就会慢慢按照这种语言的思维模式进行思考。所以，后来当你遇到任何一种有重大差异的语言，即使那种语言本身没有任何不对的地方，你也觉得它极其难用。缺乏经验的程序员对于各种语言优缺点的判断经常被这种心态误导 有些人认为编程语言应该防止程序员干蠢事，另一些人则认为程序员应该可以用编程语言干一切他们想干的事。Java是前一个阵营的代表，Perl是后一个阵营的代表","link":"/2019/06/16/读《黑客与画家》/"},{"title":"理解Function和BiFunction","text":"Function Function作为一个函数式接口，主要方法apply接受一个参数，返回一个值 1234567891011@FunctionalInterfacepublic interface Function&lt;T, R&gt; { /** * Applies this function to the given argument. * * @param t the function argument * @return the function result */ R apply(T t);} 这里需要注意的是定义的范型，这个接口中声明了2个类型，其中T为方法参数类型，R为方法返回类型 同时该接口包含了2个default方法，用来对函数进行组合 1234567891011&lt;!--这个方法用来组合一个函数，被组合的函数先执行，--&gt;default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) { Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v));}&lt;!--同样这也用来组合一个函数，区别在于被组合的函数后执行--&gt;default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t));} 使用 上面的例子中声明了2个函数f1和f2，分别使用不同的组合方法。 12345678910@Testpublic void test() { Function&lt;Integer, Integer&gt; f1 = x -&gt; {return x * x;}; Function&lt;Integer, Integer&gt; f2 = x -&gt; {return x + x;}; //（3+3）*（3+3）= 36 System.out.println(f1.compose(f2).apply(3)); //（3*3）+（3*3）=18 System.out.println(f1.andThen(f2).apply(3));} BiFunction BiFunction也是一个函数式接口，和Function接口不同的是，它在接口中声明了3个泛型，其中前两个作为方法参数类型，最后一个作为返回类型 123456789101112@FunctionalInterfacepublic interface BiFunction&lt;T, U, R&gt; { /** * Applies this function to the given arguments. * * @param t the first function argument * @param u the second function argument * @return the function result */ R apply(T t, U u);} 同时在BiFunction接口中定义了一个default方法andThen,用来与Function函数进行组合 使用 定义一个函数实现，然后对BiFunction和Function进行组合 12345678@Testpublic void test() { BiFunction&lt;String, String, String&gt; f1 = (x,y) -&gt; \"world \" + x + y; Function&lt;String, String&gt; f2 = (x) -&gt; \"hello \" + x; System.out.println(f1.apply(\"zhang\", \"san\")); System.out.println(f1.andThen(f2).apply(\"li\", \"si\"));} 其它函数式接口在理解了Function接口之后再去理解这些函数接口道理都是一样的，主要区别在于接口声明中范型的的用法 Supplier这个接口用来生产一个T类型的对象 12345678910@FunctionalInterfacepublic interface Supplier&lt;T&gt; { /** * Gets a result. * * @return a result */ T get();} Consumer这个接口用来消费一个对象，无返回 12345678910@FunctionalInterfacepublic interface Consumer&lt;T&gt; { /** * Performs this operation on the given argument. * * @param t the input argument */ void accept(T t);} Predicate这个接口用来测试一个对象,返回值为一个boolean类型 123456789101112@FunctionalInterfacepublic interface Predicate&lt;T&gt; { /** * Evaluates this predicate on the given argument. * * @param t the input argument * @return {@code true} if the input argument matches the predicate, * otherwise {@code false} */ boolean test(T t);}","link":"/2019/05/20/理解Function和BiFunction/"},{"title":"理解CompletableFuture","text":"CompletableFuture是java8新增的一个接口，它提供了对异步程序执行的另一种方式。 理解Future在结构上看CompletableFuture实现了Future和CompletionStage这两个接口，先来看看Future接口提供的功能 12345678public interface Future&lt;V&gt; { boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;} Future是一个将来对象，用来接收异步操作执行后的结果，提供了三个方法用来获取当前异步线程执行的状态。而调用get()方法会阻塞异步线程，直到执行完成获取结果。 但在实际异步编程的时候，使用起来并不是那么特别好用。 一个简单的例子： 123456789101112131415161718192021@Testpublic void test5() throws ExecutionException, InterruptedException { ExecutorService executorService = Executors.newFixedThreadPool(3); Future&lt;String&gt; f = executorService.submit(()-&gt;{ System.out.println(Thread.currentThread().getName()); try { Thread.sleep(3000L); } catch (InterruptedException e) { e.printStackTrace(); } return \"async finished\"; }); try { Thread.sleep(5000L); } catch (InterruptedException e) { e.printStackTrace(); } String r = f.get(); System.out.println(r);} 理解CompletionStage上面提到了CompletableFuture实现的另外一个接口是CompletionStage,从字面上看这是一个完成阶段，在这个接口中声明了许多的方法 虽然这个接口的方法很多，但是很有规律，总的来说，分为对异步结果分别进行响应()，结果转换(Function, BiFunction)，结果消费(Consumer, BiConsumer)，以及异常的处理等。 对异步结果进行转换1public &lt;U&gt; CompletionStage&lt;U&gt; thenApply(Function&lt;? super T,? extends U&gt; fn); 例子: 12345678@Testpublic void test() { String result = CompletableFuture.supplyAsync(()-&gt; \"Hello\").thenApplyAsync(s-&gt;{ System.out.println(Thread.currentThread().getName()); return s+\"world\"; }).join(); System.out.println(result);} 对异步结果进行消费1public CompletionStage&lt;Void&gt; thenAccept(Consumer&lt;? super T&gt; action); 例子： 1234@Testpublic void test() { CompletableFuture.supplyAsync(()-&gt; \"Hello\").thenAccept(System.out::println);} 对异步结果不关心，执行下一个操作1public CompletionStage&lt;Void&gt; thenRun(Runnable action); 例子: 1234@Testpublic void test() { CompletableFuture.supplyAsync(()-&gt; \"Hello\").thenRun(()-&gt; System.out.println(\"World\"));} 将CompletionStage函数作为参数12public &lt;U&gt; CompletionStage&lt;U&gt; thenCompose (Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn); 例子: 12345@Testpublic void test() { String combine = CompletableFuture.supplyAsync(()-&gt; \"Hello\").thenComposeAsync((x)-&gt; CompletableFuture.supplyAsync(()-&gt; x + \"World\")).join(); System.out.println(combine);} 组合其它的CompletionStage，使用BiFunction计算转换123public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombine (CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn); 例子: 12345@Testpublic void test() { String combine = CompletableFuture.supplyAsync(()-&gt; \"Hello\").thenCombine(CompletableFuture.supplyAsync(()-&gt; \"World\"), (x, y)-&gt; x+y).join(); System.out.println(combine);} 组合其它的CompletionStage，使用BiConsumer消费123public &lt;U&gt; CompletionStage&lt;Void&gt; thenAcceptBoth (CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T, ? super U&gt; action); 例子: 123456@Testpublic void test() { CompletableFuture.supplyAsync(()-&gt; \"Hello\").thenAcceptBoth(CompletableFuture.supplyAsync(()-&gt; \"World\"), (x, y)-&gt; { System.out.println(x+y); });} 组合其它的CompletionStage，都完成后执行新的任务12public CompletionStage&lt;Void&gt; runAfterBoth(CompletionStage&lt;?&gt; other, Runnable action); 例子: 123456@Testpublic void test() { CompletableFuture.supplyAsync(()-&gt; \"Hello\").runAfterBoth(CompletableFuture.supplyAsync(()-&gt; \"World\"), ()-&gt; { System.out.println(\"ok\"); });} 组合其它的CompletionStage，用计算快的CompletionStage结果进行后续计算转换123public &lt;U&gt; CompletionStage&lt;U&gt; applyToEither (CompletionStage&lt;? extends T&gt; other, Function&lt;? super T, U&gt; fn); 例子: 12345@Testpublic void test() { String e = CompletableFuture.supplyAsync(()-&gt; \"Hello\").applyToEither(CompletableFuture.supplyAsync(()-&gt; \"World\"), (x)-&gt; x).join(); System.out.println(e);} 组合其它的CompletionStage，用计算快的CompletionStage结果进行消费123public CompletionStage&lt;Void&gt; acceptEither (CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action); 例子: 1234@Testpublic void test() { CompletableFuture.supplyAsync(()-&gt; \"Hello\").acceptEither(CompletableFuture.supplyAsync(()-&gt; \"World\"), System.out::println);} 组合其它的CompletionStage，其中一个完成后，继续后续任务12public CompletionStage&lt;Void&gt; runAfterEither(CompletionStage&lt;?&gt; other, Runnable action); 例子: 1234@Testpublic void test() { CompletableFuture.supplyAsync(()-&gt; \"Hello\").runAfterEither(CompletableFuture.supplyAsync(()-&gt; \"World\"), ()-&gt; System.out.println(\"Hi\"));} 函数完成异常, 使用exceptionally进行熔断12public CompletionStage&lt;T&gt; exceptionally (Function&lt;Throwable, ? extends T&gt; fn); 例子: 12345678910111213@Testpublic void test() { String r = CompletableFuture.supplyAsync(()-&gt; { if (true) { throw new RuntimeException(\"Error Test\"); } return \"Hello\"; }).exceptionally(e -&gt; { e.printStackTrace(); return \"World\"; }).join(); System.out.println(r);} 当运行完成时，对正常和异常的结果进行消费12public CompletionStage&lt;T&gt; whenComplete (BiConsumer&lt;? super T, ? super Throwable&gt; action); 例子: 123456789101112@Testpublic void test() { CompletableFuture.supplyAsync(()-&gt; { if (true) { throw new RuntimeException(\"Error Test\"); } return \"Hello\"; }).whenComplete((x, e)-&gt; { System.out.println(x); e.printStackTrace(); });} 对正常和异常的运行结果进行转换12public &lt;U&gt; CompletionStage&lt;U&gt; handle (BiFunction&lt;? super T, Throwable, ? extends U&gt; fn); 例子: 12345678910111213@Testpublic void test() { CompletableFuture.supplyAsync(()-&gt; { if (true) { throw new RuntimeException(\"Error Test\"); } return \"Hello\"; }).handle((x, e)-&gt; { System.out.println(x); e.printStackTrace(); return \"\"; });} 理解CompletableFuture在看完Future和CompletionStage接口之后，我们继续看CompletableFuture里面定义的一些公共方法 构造CompletableFuture 空构造方法构造一个非完成状态的CompletableFuture 通过一个给定的对象创建一个完成状态的CompletableFuture 通过接受一个Supplier接口函数创建","link":"/2019/05/20/理解CompletableFuture/"},{"title":"记录一次问题解决的过程(一)","text":"问题描述在A.example.com网站中通过超链接链接到B.example.com(B系统是一个开源系统提供的web管理界面)实现的方式是通过Htmla标签做跳转，实际测试的过程中，点击超链接，出现下述页面。从页面上看提示重定向的次数过多。 日志继续解决问题，观察Nginx和浏览器控制台的日志，发现请求产生了死循环。正常通过url地址访问B网站正常。通过A网站跳转到B网站就不行。 对比分析Http请求，除了跳转的请求包含了referer字段外，其它信息完全一样，草难道问题出在这？ 猜测难道B网站做了referer来源限制，B网站也不是内部开发 解决方案在代理层，强制修改访问B网站的referer为B.example.com, 默认为A.example.com. 修改代理配置设置代理请求头Referer 1proxy_set_header Referer &quot;http://proxied-domain-here.com&quot;;","link":"/2019/05/31/记录一次问题解决的过程(一)/"},{"title":"JUnit5入门学习(二)","text":"前面已经在Maven构建的项目中运行了第一个Junit5测试用例，本篇主要记录学习测试用例的写法。 测试类和方法Test Class: 任何顶级类，静态的成员类，内部类必须包含至少一个测试方法，并且这个测试方法不能是抽象的且只能有一个构造器 Test Method: 任何实例的方法都可以直接注解或者被元注解包含@Test @RepeatedTest @ParameterizedTest @TestFactory @TestTemplate 后面会对这些一一说到。 Lifecycle Method: 和测试方法一样，生命周期方法包含的注解有 @BeforeAll @AfterAll @BeforeEach @AfterEach 测试方法和生命周期方法不需要声明在测试类本身，也可以在父类或者接口上，测试方法和测试类不可以有返回值，并且不能是私有的方法 一个标准的测试类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import static org.junit.jupiter.api.Assertions.fail;import static org.junit.jupiter.api.Assumptions.assumeTrue;import org.junit.jupiter.api.AfterAll;import org.junit.jupiter.api.AfterEach;import org.junit.jupiter.api.BeforeAll;import org.junit.jupiter.api.BeforeEach;import org.junit.jupiter.api.Disabled;import org.junit.jupiter.api.Test;class StandardTests { @BeforeAll static void initAll() { } @BeforeEach void init() { } @Test void succeedingTest() { } @Test void failingTest() { fail(\"a failing test\"); } @Test @Disabled(\"for demonstration purposes\") void skippedTest() { // not executed } @Test void abortedTest() { assumeTrue(\"abc\".contains(\"Z\")); fail(\"test should have been aborted\"); } @AfterEach void tearDown() { } @AfterAll static void tearDownAll() { }} 需要注意的是: @BeforeAll和@AfterAll修饰的是静态方法 @BeforeAll和@BeforeEach的最大的区别在于运行该测试类，前者只会执行一次，后者对于每个测试方法测试前都会执行一次。After*同理 内部类方法不用@BeforeAll和@AfterAll修饰，原因是内部类不能包含静态方法 显示名生成器测试类或者测试方法通过@DisplayName修饰可以自定义report显示的名称，复杂的名称生成器通过@DisplayNameGeneration来实现 123456@DisplayNameGeneration(IndicativeSentences.class)class xxx {}static class IndicativeSentences extends DisplayNameGenerator.ReplaceUnderscores { ...} 断言和Junit4相比, 一些断言方法里支持了函数参数，这个函数是Supplier, 所有的断言方法都在类org.junit.jupiter.api.Assertions里面 fail() assertTrue() assertFalse() assertNull() assertNotNull() assertEquals() assertNotEquals() assertArrayEquals() assertIterableEquals() assertLinesMatch() assertSame() assertNotSame() assertAll() assertThrows() assertDoesNotThrows() assertTimeout() assertTimeoutPreemptively() 算上方法重载有点多。。没有逐个去测试了 第三方断言库，后面再看 AssertJ Truth Hamcrest 假定关于假定和断言的区别见参考，最大的区别在于假定失败不会影响到整个测试类其它测试方法的执行，而断言失败则会导致整个测试类失败。 所有的Assumptions包含在org.junit.jupiter.api.Assumptions类中 禁用测试对于某些测试类或者测试方法需要暂停执行测试可以通过@Disabled(&quot;Disabled until bug #99 has been fixed&quot;)修饰，可以作用在类(包含内部类)和方法(各种方法)上 测试运行条件简单来说就是为测试用例的执行添加前置条件，如果条件满足则执行，条件不满足则跳过不执行。 Operating System Conditions在类或者方法上添加@EnabledOnOs(OS.MAC)或@DisabledOnOs Java Runtime Environment Conditions在类或者方法上添加@EnabledOnJre({ JAVA_9, JAVA_10 }) 或 @DisabledOnJre(JAVA_9) System Property Conditions1234567891011@Test@EnabledIfSystemProperty(named = \"os.arch\", matches = \".*64.*\")void onlyOn64BitArchitectures() { // ...}@Test@DisabledIfSystemProperty(named = \"ci-server\", matches = \"true\")void notOnCiServer() { // ...} Environment Variable Conditions1234567891011@Test@EnabledIfEnvironmentVariable(named = \"ENV\", matches = \"staging-server\")void onlyOnStagingServer() { // ...}@Test@DisabledIfEnvironmentVariable(named = \"ENV\", matches = \".*development.*\")void notOnDeveloperWorkstation() { // ...} Script-based Conditions示例 需要注意的是这个api还处于实验阶段 测试方法执行顺序这里是用来控制测试类中多个测试方法的执行顺序 123456789101112131415161718192021222324252627import org.junit.jupiter.api.MethodOrderer.OrderAnnotation;import org.junit.jupiter.api.Order;import org.junit.jupiter.api.Test;import org.junit.jupiter.api.TestMethodOrder;@TestMethodOrder(OrderAnnotation.class) //1class OrderedTestsDemo { @Test @Order(1) //2 void nullValues() { // perform assertions against null values } @Test @Order(2) void emptyValues() { // perform assertions against empty values } @Test @Order(3) void validValues() { // perform assertions against valid values }} 添加 @TestMethodOrder注解并制定排序方式，上面的例子用的是Order注解 添加 @Order(1) 声明执行的顺序 除了OrderAnnotation外还有Alphanumeric和Random 内部类测试@Nested注解作用在内部类上来表达内部类的测试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import static org.junit.jupiter.api.Assertions.assertEquals;import static org.junit.jupiter.api.Assertions.assertFalse;import static org.junit.jupiter.api.Assertions.assertThrows;import static org.junit.jupiter.api.Assertions.assertTrue;import java.util.EmptyStackException;import java.util.Stack;import org.junit.jupiter.api.BeforeEach;import org.junit.jupiter.api.DisplayName;import org.junit.jupiter.api.Nested;import org.junit.jupiter.api.Test;@DisplayName(\"A stack\")class TestingAStackDemo { Stack&lt;Object&gt; stack; @Test @DisplayName(\"is instantiated with new Stack()\") void isInstantiatedWithNew() { new Stack&lt;&gt;(); } @Nested @DisplayName(\"when new\") class WhenNew { @BeforeEach void createNewStack() { stack = new Stack&lt;&gt;(); } @Test @DisplayName(\"is empty\") void isEmpty() { assertTrue(stack.isEmpty()); } @Test @DisplayName(\"throws EmptyStackException when popped\") void throwsExceptionWhenPopped() { assertThrows(EmptyStackException.class, stack::pop); } @Test @DisplayName(\"throws EmptyStackException when peeked\") void throwsExceptionWhenPeeked() { assertThrows(EmptyStackException.class, stack::peek); } @Nested @DisplayName(\"after pushing an element\") class AfterPushing { String anElement = \"an element\"; @BeforeEach void pushAnElement() { stack.push(anElement); } @Test @DisplayName(\"it is no longer empty\") void isNotEmpty() { assertFalse(stack.isEmpty()); } @Test @DisplayName(\"returns the element when popped and is empty\") void returnElementWhenPopped() { assertEquals(anElement, stack.pop()); assertTrue(stack.isEmpty()); } @Test @DisplayName(\"returns the element when peeked but remains not empty\") void returnElementWhenPeeked() { assertEquals(anElement, stack.peek()); assertFalse(stack.isEmpty()); } } }} 需要注意的是，测试方法的声明周期对于内部类测试方法，完整的执行顺序为 @BeforeAll-&gt; 外部 @BeforeEach-&gt; 内部类@BeforeEach-&gt;@Test-&gt;内部类 @AfterEach -&gt; 外部 @AfterEach-&gt; @AfterAll 依赖注入意思就是测试类的构造方法或者测试方法可以运行过程中，自动被注入对象，目前，JUnit内置类3类对象的自动注入。 TestInfo 1234567891011121314151617TestInfoDemo(TestInfo testInfo) { assertEquals(\"TestInfo Demo\", testInfo.getDisplayName());}@BeforeEachvoid init(TestInfo testInfo) { String displayName = testInfo.getDisplayName(); assertTrue(displayName.equals(\"TEST 1\") || displayName.equals(\"test2()\"));}@Test@DisplayName(\"TEST 1\")@Tag(\"my-tag\")void test1(TestInfo testInfo) { assertEquals(\"TEST 1\", testInfo.getDisplayName()); assertTrue(testInfo.getTags().contains(\"my-tag\"));} RepetitionInfo: 获取重复执行时，当前执行次数与总次数等信息 TestReporter 暂时没想到使用场景，另外可以自定义，更多的参考文档。 重复测试JUnit提供了对一个测试方法重复测试的能力，emmm，你不用写for循环来回执行 1234@RepeatedTest(value = 10, name = \"{displayName} {currentRepetition} -{totalRepetitions}\")void repeatedTest() { // ...} 需要注意的是上述@RepeatedTest注解属性name里面有几个变量，可以自定义Report 参考1. 假设机制（Assumption）的优点","link":"/2019/06/11/JUnit5入门学习(二)/"},{"title":"构建基于kubernetes的DevOps平台(一)","text":"在开始学习k8s前，需要部署一套k8s系统，部署k8s主要有2种方式(我知道的，可能更多)，一种是通过二进制部署，另外一种是通过kubeadm进行部署，这里我们使用kubeadm进行部署。 硬件准备这里我想通过kubeadm部署一个多master的k8s集群，这也更加符合生产环境的需要。更多的k8s的基础知识不想多做赘述。 服务器及IP Hostname Role Ip k8s-m1 master1 172.16.26.81 k8s-m2 master2 172.16.26.82 k8s-m3 master3 172.16.26.83 k8s-n1 node1 172.16.26.121 k8s-n2 node2 172.16.26.122 k8s-n3 node3 172.16.26.123 浮动IP(VIP): 172.16.26.80 环境准备系统配置安装的初始操作系统为centos7.5桌面版，里面已经包含了一部分的系统自带软件，如wget等, 系统配置需要在所有节点执行 关闭SELinux、防火墙1234systemctl stop firewalldsystemctl disable firewalldsetenforce 0sed -i \"s/SELINUX=enforcing/SELINUX=disabled/g\" /etc/selinux/config 关闭系统的Swap123swapoff -ayes | cp /etc/fstab /etc/fstab_bakcat /etc/fstab_bak |grep -v swap &gt; /etc/fstab 网络配置12345678modprobe br_netfilterecho \"\"\"vm.swappiness = 0net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1\"\"\" &gt; /etc/sysctl.confsysctl -p 内核升级 安装内核依赖包 1[ ! -f /usr/bin/perl ] &amp;&amp; yum install perl -y 升级内核需要使用 elrepo 的yum 源,首先我们导入 elrepo 的 key并安装 elrepo 源 12 rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.orgrpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm 查看可用的内核 1yum --disablerepo=\"*\" --enablerepo=\"elrepo-kernel\" list available --showduplicates 最新内核安装 12 yum --disablerepo=\"*\" --enablerepo=\"elrepo-kernel\" list available --showduplicates | grep -Po '^kernel-ml.x86_64\\s+\\K\\S+(?=.el7)'yum --disablerepo=\"*\" --enablerepo=elrepo-kernel install -y kernel-ml{,-devel} 修改内核默认的启动顺序 1grub2-set-default 0 &amp;&amp; grub2-mkconfig -o /etc/grub2.cfg 重启后查看当前内核 12rebootgrubby --default-kernel IPVS安装IPVS 1yum install ipvsadm ipset sysstat conntrack libseccomp -y 设置加载的内核模块 123456789ipvs_modules=\"ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack\"for kernel_module in \\${ipvs_modules}; do /sbin/modinfo -F filename \\${kernel_module} &gt; /dev/null 2&gt;&amp;1 if [ $? -eq 0 ]; then /sbin/modprobe \\${kernel_module} fidoneEOFchmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep ip_vs k8s参数设置12345678910111213141516171819202122232425262728293031cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confnet.ipv4.tcp_keepalive_time = 600net.ipv4.tcp_keepalive_intvl = 30net.ipv4.tcp_keepalive_probes = 10net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1net.ipv6.conf.lo.disable_ipv6 = 1net.ipv4.neigh.default.gc_stale_time = 120net.ipv4.conf.all.rp_filter = 0net.ipv4.conf.default.rp_filter = 0net.ipv4.conf.default.arp_announce = 2net.ipv4.conf.lo.arp_announce = 2net.ipv4.conf.all.arp_announce = 2net.ipv4.ip_forward = 1net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_syn_backlog = 1024net.ipv4.tcp_synack_retries = 2net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.netfilter.nf_conntrack_max = 2310720fs.inotify.max_user_watches=89100fs.may_detach_mounts = 1fs.file-max = 52706963fs.nr_open = 52706963net.bridge.bridge-nf-call-arptables = 1vm.swappiness = 0vm.overcommit_memory=1vm.panic_on_oom=0EOFsysctl --system 软件安装Docker安装123456789101112# 安装docker, 我用的是18.06.3-ceyum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repoyum makecache fast## 列出Docker版本yum list docker-ce --showduplicates | sort -r## 安装指定版本sudo yum install docker-ce-&lt;VERSION_STRING&gt; Kubernetes相关组件安装1234567891011cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOFyum install -y kubelet kubeadm kubectl ebtables Keepalived Haproxy安装(node节点不需要安装) 安装1yum install -y socat keepalived haproxy 配置变量设置12345678910111213cd ~/# 创建集群信息文件echo &quot;&quot;&quot;CP0_IP=172.16.26.81CP1_IP=172.16.26.82CP2_IP=172.16.26.83VIP=172.16.26.80NET_IF=eth0CIDR=10.244.0.0/16&quot;&quot;&quot; &gt; ./cluster-info# 配置haproxy和keepeelivedbash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/hnbcao/kubeadm-ha-master/v1.14.0/keepalived-haproxy.sh)&quot; 服务开机启动12345678910# 启动dockersed -i \"13i ExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPT\" /usr/lib/systemd/system/docker.servicesystemctl daemon-reloadsystemctl enable dockersystemctl start docker# 设置kubelet开机启动systemctl enable kubeletsystemctl enable keepalivedsystemctl enable haproxy 开始部署master节点初始化在开始前配置master1到其它节点的免密登陆，简单-略过 初始化master1 12345678910111213141516171819202122232425echo \"\"\"apiVersion: kubeadm.k8s.io/v1beta1kind: ClusterConfigurationkubernetesVersion: v1.13.0controlPlaneEndpoint: \"${VIP}:8443\"maxPods: 100networkPlugin: cniimageRepository: registry.aliyuncs.com/google_containersapiServer: certSANs: - ${CP0_IP} - ${CP1_IP} - ${CP2_IP} - ${VIP}networking: # This CIDR is a Calico default. Substitute or remove for your CNI provider. podSubnet: ${CIDR}---#apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationmode: ipvs\"\"\" &gt; /etc/kubernetes/kubeadm-config.yamlkubeadm init --config /etc/kubernetes/kubeadm-config.yamlmkdir -p $HOME/.kubecp -f /etc/kubernetes/admin.conf ${HOME}/.kube/config 拷贝相关证书到master2、master3 12345678910111213141516for index in 1 2; do ip=${IPS[${index}]} ssh $ip \"mkdir -p /etc/kubernetes/pki/etcd; mkdir -p ~/.kube/\" scp /etc/kubernetes/pki/ca.crt $ip:/etc/kubernetes/pki/ca.crt scp /etc/kubernetes/pki/ca.key $ip:/etc/kubernetes/pki/ca.key scp /etc/kubernetes/pki/sa.key $ip:/etc/kubernetes/pki/sa.key scp /etc/kubernetes/pki/sa.pub $ip:/etc/kubernetes/pki/sa.pub scp /etc/kubernetes/pki/front-proxy-ca.crt $ip:/etc/kubernetes/pki/front-proxy-ca.crt scp /etc/kubernetes/pki/front-proxy-ca.key $ip:/etc/kubernetes/pki/front-proxy-ca.key scp /etc/kubernetes/pki/etcd/ca.crt $ip:/etc/kubernetes/pki/etcd/ca.crt scp /etc/kubernetes/pki/etcd/ca.key $ip:/etc/kubernetes/pki/etcd/ca.key scp /etc/kubernetes/admin.conf $ip:/etc/kubernetes/admin.conf scp /etc/kubernetes/admin.conf $ip:~/.kube/config ssh ${ip} \"${JOIN_CMD} --experimental-control-plane\"done master2、master3加入节点 1JOIN_CMD=`kubeadm token create --print-join-command` ssh ${ip} \"${JOIN_CMD} --experimental-control-plane\" node节点加入获取节点加入命令 1kubeadm token create --print-join-command 分别在node上执行获得的命令 集群网络安装网络插件选择 网络插件安装 遇到的问题 docker mtu 的配置 配置/etc/docker/daemon.json 1234567891011121314{ &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;registry-mirrors&quot;: [&quot;https://axejqb6p.mirror.aliyuncs.com&quot;], &quot;mtu&quot;: 1450, &quot;storage-driver&quot;: &quot;overlay2&quot;, &quot;storage-opts&quot;: [ &quot;overlay2.override_kernel_check=true&quot; ], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: { &quot;max-size&quot;: &quot;100m&quot;, &quot;max-file&quot;: &quot;3&quot; }} vip的转移 我当前使用的配置 /etc/haproxy/haproxy.cfg 1234567891011121314151617181920212223242526272829303132333435363738global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/statsdefaults mode tcp log global option tcplog option dontlognull option redispatch retries 3 timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout check 10s maxconn 3000listen stats mode http bind :10086 stats enable stats uri /admin?stats stats auth admin:admin stats admin if TRUEfrontend k8s_https *:8443 mode tcp maxconn 2000 default_backend https_sribackend https_sri balance roundrobin server master1-api 172.16.26.81:6443 check inter 10000 fall 2 rise 2 weight 1 server master2-api 172.16.26.82:6443 check inter 10000 fall 2 rise 2 weight 1 server master3-api 172.16.26.83:6443 check inter 10000 fall 2 rise 2 weight 1 /etc/keepalived/check_haproxy.sh 123456789#!/bin/bashVIRTUAL_IP=172.16.26.80errorExit() { echo &quot;*** $*&quot; 1&gt;&amp;2 exit 1}if ip addr | grep -q $VIRTUAL_IP ; then curl -s --max-time 2 --insecure https://${VIRTUAL_IP}:8443/ -o /dev/null || errorExit &quot;Error GET https://${VIRTUAL_IP}:8443/&quot;fi /etc/keepalived/keepalived.conf 12345678910111213141516171819202122232425vrrp_script haproxy-check { script &quot;/bin/bash /etc/keepalived/check_haproxy.sh&quot; interval 3 weight -2 fall 10 rise 2}vrrp_instance haproxy-vip { state BACKUP priority 101 interface eth0 virtual_router_id 47 advert_int 3 unicast_peer { 172.16.26.81 172.16.26.82 172.16.26.83 } virtual_ipaddress { 172.16.26.80 } track_script { haproxy-check }} 参考 官方文档 社区教程","link":"/2019/05/27/构建基于kubernetes的DevOps平台(一)/"}],"tags":[{"name":"guava","slug":"guava","link":"/tags/guava/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"junit5","slug":"junit5","link":"/tags/junit5/"},{"name":"jenkins","slug":"jenkins","link":"/tags/jenkins/"},{"name":"helm","slug":"helm","link":"/tags/helm/"},{"name":"devops","slug":"devops","link":"/tags/devops/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"springcloud","slug":"springcloud","link":"/tags/springcloud/"},{"name":"springframework","slug":"springframework","link":"/tags/springframework/"},{"name":"network","slug":"network","link":"/tags/network/"},{"name":"reading","slug":"reading","link":"/tags/reading/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"vim","slug":"vim","link":"/tags/vim/"},{"name":"grpc","slug":"grpc","link":"/tags/grpc/"},{"name":"travis-ci","slug":"travis-ci","link":"/tags/travis-ci/"},{"name":"openshift","slug":"openshift","link":"/tags/openshift/"},{"name":"work","slug":"work","link":"/tags/work/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"kubernetes","slug":"kubernetes","link":"/tags/kubernetes/"}],"categories":[{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Test","slug":"Java/Test","link":"/categories/Java/Test/"},{"name":"CI","slug":"CI","link":"/categories/CI/"},{"name":"Functional","slug":"Java/Functional","link":"/categories/Java/Functional/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"Network","slug":"Network","link":"/categories/Network/"},{"name":"Reading","slug":"Reading","link":"/categories/Reading/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"Jenkins","slug":"CI/Jenkins","link":"/categories/CI/Jenkins/"},{"name":"gRPC","slug":"gRPC","link":"/categories/gRPC/"},{"name":"Travis-ci","slug":"CI/Travis-ci","link":"/categories/CI/Travis-ci/"},{"name":"CloudComputing","slug":"CloudComputing","link":"/categories/CloudComputing/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","link":"/categories/Spring/SpringCloud/"},{"name":"Concurrent","slug":"Java/Concurrent","link":"/categories/Java/Concurrent/"},{"name":"Work","slug":"Work","link":"/categories/Work/"},{"name":"SpringFramework","slug":"Spring/SpringFramework","link":"/categories/Spring/SpringFramework/"},{"name":"OpenShift","slug":"CloudComputing/OpenShift","link":"/categories/CloudComputing/OpenShift/"},{"name":"Kubernetes","slug":"CloudComputing/Kubernetes","link":"/categories/CloudComputing/Kubernetes/"}]}